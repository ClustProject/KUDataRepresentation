{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import main_data_representation as mdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. model = ts2vec\n",
    "config1 = {\n",
    "    \"model\": 'ts2vec',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/ts2vec.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 64,  # encoder의 hidden dimension, int(default: 64, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"num_epochs\": 30,  # 학습 epoch 횟수, int(default: 30, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 2. model = ts_tcc\n",
    "config2 = {\n",
    "    \"model\": 'ts_tcc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/ts_tcc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 100,  # temporal / contextual contrasting 모듈의 hidden dimension, int(default: 100, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"timesteps\": 6,  # temporal contrasting 모듈에서 미래 예측할 시점의 길이, int(default: 6, 범위: 1 이상)\n",
    "        \"num_epochs\": 30,  # 학습 epoch 횟수, int(default: 30, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        \"jitter_scale_ratio\": 1.1,  # time series data augementation 중 weak augementation의 강도, float(default: 1.1, default 값 사용 권장)\n",
    "        \"jitter_ratio\": 0.8,  # time series data augementation 중 strong augementation의 강도, float(default: 0.8, default 값 사용 권장)\n",
    "        \"max_seg\": 8  # strong augementation에서 permutation 진행시 데이터의 최대 분할 개수, int(default: 8, default 값 사용 권장)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 3. model = rae_mepc\n",
    "config3 = {\n",
    "    \"model\": 'rae_mepc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/rae_mepc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"window_size\": 32,  # 모델의 input sequence 길이, int(default: 32, 범위: 0 이상 & 원래 데이터의 sequence 길이 이하)\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"enc_nlayers\": 3,  # multi-resolution encoder를 구성하는 sub-encoder의 개수, int(default: 3, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"dec_nlayers\": 3,  # multi-resolution decoder를 구성하는 sub-decoder의 개수, int(default: 3, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"tau\": 4,  # multi-resolution encoder 및 decoder의 resolution를 조절하는 값, int(default: 4, 범위: 2 이상, default 값 사용 권장)\n",
    "        \"num_epochs\": 30,  # 학습 epoch 횟수, int(default: 30, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\"  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 4. model = stoc\n",
    "config4 = {\n",
    "    \"model\": 'stoc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/stoc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": { \n",
    "        \"window_size\": 32,  # 모델의 input sequence 길이, int(default: 32, 범위: 0 이상 & 원래 데이터의 sequence 길이 이하)\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 256,  # encoder의 hidden dimension, int(default: 356, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"forecast_step\": 1,  # 미래 시계열 데이터에 대하여 예측할 시점의 길이, int(default: 6, 범위: 1 이상)\n",
    "        \"num_epochs\": 30,  # 학습 epoch 횟수, int(default: 30, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택, \n",
    "        \"patience\": 10,  # 예측 모델 학습 시, 사전 설정한 epoch 동안 loss가 감소하지 않으면 학습 조기 중단, int(default: 10, 범위: 1 이상 num_epochs 미만)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset_dir = {\n",
    "    \"train\": './data/X_train.pkl',\n",
    "    \"test\": './data/X_test.pkl'\n",
    "}\n",
    "\n",
    "# train/test 데이터 불러오기 (pickle 형태)\n",
    "# shape=(# observations, # features, # time steps)\n",
    "train_data = pickle.load(open(dataset_dir[\"train\"], 'rb'))  # shape=(7352, 9, 128)\n",
    "test_data = pickle.load(open(dataset_dir[\"test\"], 'rb'))  # shape=(2947, 9, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=4.936868476867676\n",
      "Epoch #1: validation loss=4.943576335906982\n",
      "\n",
      "Epoch #2: train loss=4.627585792541504\n",
      "Epoch #2: validation loss=4.884347915649414\n",
      "\n",
      "Epoch #3: train loss=4.79036808013916\n",
      "Epoch #3: validation loss=4.623116493225098\n",
      "\n",
      "Epoch #4: train loss=4.55261926651001\n",
      "Epoch #4: validation loss=4.731514930725098\n",
      "\n",
      "Epoch #5: train loss=4.5294112205505375\n",
      "Epoch #5: validation loss=4.675436973571777\n",
      "\n",
      "Epoch #6: train loss=4.473555088043213\n",
      "Epoch #6: validation loss=4.2629075050354\n",
      "\n",
      "Epoch #7: train loss=4.341904354095459\n",
      "Epoch #7: validation loss=4.463427543640137\n",
      "\n",
      "Epoch #8: train loss=4.481424331665039\n",
      "Epoch #8: validation loss=4.20048189163208\n",
      "\n",
      "Epoch #9: train loss=4.2812458038330075\n",
      "Epoch #9: validation loss=4.146800994873047\n",
      "\n",
      "Epoch #10: train loss=4.198643016815185\n",
      "Epoch #10: validation loss=4.0082621574401855\n",
      "\n",
      "Epoch #11: train loss=4.109360694885254\n",
      "Epoch #11: validation loss=4.026050567626953\n",
      "\n",
      "Epoch #12: train loss=4.023466968536377\n",
      "Epoch #12: validation loss=3.872009515762329\n",
      "\n",
      "Epoch #13: train loss=3.79688982963562\n",
      "Epoch #13: validation loss=3.7302920818328857\n",
      "\n",
      "Epoch #14: train loss=3.729768896102905\n",
      "Epoch #14: validation loss=3.6859381198883057\n",
      "\n",
      "Epoch #15: train loss=3.6393598079681397\n",
      "Epoch #15: validation loss=3.4673187732696533\n",
      "\n",
      "Epoch #16: train loss=3.5942234992980957\n",
      "Epoch #16: validation loss=3.4088637828826904\n",
      "\n",
      "Epoch #17: train loss=3.341631364822388\n",
      "Epoch #17: validation loss=3.2839369773864746\n",
      "\n",
      "Epoch #18: train loss=3.3109140396118164\n",
      "Epoch #18: validation loss=3.188924551010132\n",
      "\n",
      "Epoch #19: train loss=3.100282382965088\n",
      "Epoch #19: validation loss=3.0482640266418457\n",
      "\n",
      "Epoch #20: train loss=3.28807053565979\n",
      "Epoch #20: validation loss=3.06215238571167\n",
      "\n",
      "Epoch #21: train loss=3.142544174194336\n",
      "Epoch #21: validation loss=3.0613369941711426\n",
      "\n",
      "Epoch #22: train loss=3.113007164001465\n",
      "Epoch #22: validation loss=2.90006685256958\n",
      "\n",
      "Epoch #23: train loss=3.0539270401000977\n",
      "Epoch #23: validation loss=2.80207896232605\n",
      "\n",
      "Epoch #24: train loss=3.068688917160034\n",
      "Epoch #24: validation loss=2.8157551288604736\n",
      "\n",
      "Epoch #25: train loss=3.013983631134033\n",
      "Epoch #25: validation loss=2.746485710144043\n",
      "\n",
      "Epoch #26: train loss=2.706918954849243\n",
      "Epoch #26: validation loss=2.614478349685669\n",
      "\n",
      "Epoch #27: train loss=2.6946608543396\n",
      "Epoch #27: validation loss=2.517545700073242\n",
      "\n",
      "Epoch #28: train loss=2.8494277000427246\n",
      "Epoch #28: validation loss=2.881497859954834\n",
      "\n",
      "Epoch #29: train loss=2.681528377532959\n",
      "Epoch #29: validation loss=2.6010406017303467\n",
      "\n",
      "Epoch #30: train loss=2.683120775222778\n",
      "Epoch #30: validation loss=2.4658429622650146\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. model = ts2vec\n",
    "config = config1\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.033631</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.237707</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.490949</td>\n",
       "      <td>1.374596</td>\n",
       "      <td>0.435587</td>\n",
       "      <td>1.136328</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196531</td>\n",
       "      <td>0.033214</td>\n",
       "      <td>0.691922</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>-0.098838</td>\n",
       "      <td>0.024468</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>-0.003097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007252</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.240048</td>\n",
       "      <td>-0.012824</td>\n",
       "      <td>0.520046</td>\n",
       "      <td>1.381432</td>\n",
       "      <td>0.450673</td>\n",
       "      <td>1.141469</td>\n",
       "      <td>0.087617</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185382</td>\n",
       "      <td>0.017689</td>\n",
       "      <td>0.651348</td>\n",
       "      <td>-0.068286</td>\n",
       "      <td>0.674752</td>\n",
       "      <td>-0.049794</td>\n",
       "      <td>0.073779</td>\n",
       "      <td>-0.019720</td>\n",
       "      <td>-0.023705</td>\n",
       "      <td>-0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>-0.011001</td>\n",
       "      <td>0.213614</td>\n",
       "      <td>-0.007623</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>1.387769</td>\n",
       "      <td>0.392625</td>\n",
       "      <td>1.125404</td>\n",
       "      <td>0.175980</td>\n",
       "      <td>0.050220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207115</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.655682</td>\n",
       "      <td>-0.052771</td>\n",
       "      <td>0.665929</td>\n",
       "      <td>-0.111551</td>\n",
       "      <td>0.075382</td>\n",
       "      <td>0.033315</td>\n",
       "      <td>-0.039400</td>\n",
       "      <td>0.034564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.035661</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>0.210229</td>\n",
       "      <td>-0.016049</td>\n",
       "      <td>0.403497</td>\n",
       "      <td>1.410193</td>\n",
       "      <td>0.384614</td>\n",
       "      <td>1.139218</td>\n",
       "      <td>0.157020</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201145</td>\n",
       "      <td>-0.025719</td>\n",
       "      <td>0.614282</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>0.724790</td>\n",
       "      <td>-0.141869</td>\n",
       "      <td>0.085174</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>-0.036670</td>\n",
       "      <td>-0.034799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.018921</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.004378</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>1.409542</td>\n",
       "      <td>0.405561</td>\n",
       "      <td>1.148567</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.045878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212822</td>\n",
       "      <td>-0.015031</td>\n",
       "      <td>0.602995</td>\n",
       "      <td>-0.061823</td>\n",
       "      <td>0.733468</td>\n",
       "      <td>-0.071200</td>\n",
       "      <td>0.087868</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>-0.021300</td>\n",
       "      <td>-0.001932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.033631  0.036715  0.237707 -0.010023  0.490949  1.374596  0.435587   \n",
       "1 -0.007252  0.016638  0.240048 -0.012824  0.520046  1.381432  0.450673   \n",
       "2  0.001482 -0.011001  0.213614 -0.007623  0.483143  1.387769  0.392625   \n",
       "3 -0.035661 -0.008861  0.210229 -0.016049  0.403497  1.410193  0.384614   \n",
       "4 -0.018921  0.028302  0.227644 -0.004378  0.450709  1.409542  0.405561   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  1.136328  0.074970  0.015736  ...  0.196531  0.033214  0.691922 -0.014442   \n",
       "1  1.141469  0.087617  0.013349  ...  0.185382  0.017689  0.651348 -0.068286   \n",
       "2  1.125404  0.175980  0.050220  ...  0.207115  0.011044  0.655682 -0.052771   \n",
       "3  1.139218  0.157020  0.032520  ...  0.201145 -0.025719  0.614282 -0.061299   \n",
       "4  1.148567  0.159500  0.045878  ...  0.212822 -0.015031  0.602995 -0.061823   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0  0.643810 -0.098838  0.024468  0.000844 -0.024828 -0.003097  \n",
       "1  0.674752 -0.049794  0.073779 -0.019720 -0.023705 -0.000657  \n",
       "2  0.665929 -0.111551  0.075382  0.033315 -0.039400  0.034564  \n",
       "3  0.724790 -0.141869  0.085174  0.030246 -0.036670 -0.034799  \n",
       "4  0.733468 -0.071200  0.087868  0.016841 -0.021300 -0.001932  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406812</td>\n",
       "      <td>0.339256</td>\n",
       "      <td>-0.015329</td>\n",
       "      <td>0.297275</td>\n",
       "      <td>1.282596</td>\n",
       "      <td>1.391934</td>\n",
       "      <td>0.518683</td>\n",
       "      <td>1.089709</td>\n",
       "      <td>-0.049185</td>\n",
       "      <td>0.060886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128975</td>\n",
       "      <td>0.372564</td>\n",
       "      <td>0.665117</td>\n",
       "      <td>0.226362</td>\n",
       "      <td>0.454335</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>-0.157500</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>0.375224</td>\n",
       "      <td>0.319567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.135933</td>\n",
       "      <td>-0.082387</td>\n",
       "      <td>0.335827</td>\n",
       "      <td>1.135910</td>\n",
       "      <td>1.500563</td>\n",
       "      <td>0.396863</td>\n",
       "      <td>1.085935</td>\n",
       "      <td>0.167597</td>\n",
       "      <td>0.115023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093011</td>\n",
       "      <td>0.251897</td>\n",
       "      <td>0.592738</td>\n",
       "      <td>0.072304</td>\n",
       "      <td>0.548451</td>\n",
       "      <td>0.071378</td>\n",
       "      <td>-0.159463</td>\n",
       "      <td>0.147932</td>\n",
       "      <td>0.246739</td>\n",
       "      <td>0.162483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350981</td>\n",
       "      <td>-0.038944</td>\n",
       "      <td>-0.107906</td>\n",
       "      <td>0.359263</td>\n",
       "      <td>0.848999</td>\n",
       "      <td>1.496482</td>\n",
       "      <td>0.412876</td>\n",
       "      <td>1.090490</td>\n",
       "      <td>0.203876</td>\n",
       "      <td>0.092680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058355</td>\n",
       "      <td>0.079587</td>\n",
       "      <td>0.519686</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.682945</td>\n",
       "      <td>-0.110836</td>\n",
       "      <td>-0.091623</td>\n",
       "      <td>0.167717</td>\n",
       "      <td>0.195251</td>\n",
       "      <td>-0.022971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368999</td>\n",
       "      <td>-0.075375</td>\n",
       "      <td>-0.126406</td>\n",
       "      <td>0.401271</td>\n",
       "      <td>0.844119</td>\n",
       "      <td>1.511416</td>\n",
       "      <td>0.346760</td>\n",
       "      <td>1.093723</td>\n",
       "      <td>0.339085</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063081</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.534796</td>\n",
       "      <td>0.031849</td>\n",
       "      <td>0.660477</td>\n",
       "      <td>-0.153458</td>\n",
       "      <td>-0.127524</td>\n",
       "      <td>0.231389</td>\n",
       "      <td>0.196502</td>\n",
       "      <td>0.031155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350008</td>\n",
       "      <td>-0.052107</td>\n",
       "      <td>-0.125244</td>\n",
       "      <td>0.417671</td>\n",
       "      <td>0.714224</td>\n",
       "      <td>1.526109</td>\n",
       "      <td>0.359167</td>\n",
       "      <td>1.110752</td>\n",
       "      <td>0.296702</td>\n",
       "      <td>0.079081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069656</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>0.481167</td>\n",
       "      <td>0.067382</td>\n",
       "      <td>0.734597</td>\n",
       "      <td>-0.208285</td>\n",
       "      <td>-0.087492</td>\n",
       "      <td>0.246985</td>\n",
       "      <td>0.209821</td>\n",
       "      <td>-0.057286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.406812  0.339256 -0.015329  0.297275  1.282596  1.391934  0.518683   \n",
       "1  0.373252  0.135933 -0.082387  0.335827  1.135910  1.500563  0.396863   \n",
       "2  0.350981 -0.038944 -0.107906  0.359263  0.848999  1.496482  0.412876   \n",
       "3  0.368999 -0.075375 -0.126406  0.401271  0.844119  1.511416  0.346760   \n",
       "4  0.350008 -0.052107 -0.125244  0.417671  0.714224  1.526109  0.359167   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  1.089709 -0.049185  0.060886  ...  0.128975  0.372564  0.665117  0.226362   \n",
       "1  1.085935  0.167597  0.115023  ...  0.093011  0.251897  0.592738  0.072304   \n",
       "2  1.090490  0.203876  0.092680  ...  0.058355  0.079587  0.519686  0.001276   \n",
       "3  1.093723  0.339085  0.083968  ...  0.063081  0.101366  0.534796  0.031849   \n",
       "4  1.110752  0.296702  0.079081  ...  0.069656  0.087774  0.481167  0.067382   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0  0.454335  0.246093 -0.157500  0.084735  0.375224  0.319567  \n",
       "1  0.548451  0.071378 -0.159463  0.147932  0.246739  0.162483  \n",
       "2  0.682945 -0.110836 -0.091623  0.167717  0.195251 -0.022971  \n",
       "3  0.660477 -0.153458 -0.127524  0.231389  0.196502  0.031155  \n",
       "4  0.734597 -0.208285 -0.087492  0.246985  0.209821 -0.057286  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=17.66071319580078\n",
      "Epoch #2: validation loss=17.68142318725586\n",
      "\n",
      "Epoch #2: train loss=17.633176803588867\n",
      "Epoch #3: validation loss=18.060693740844727\n",
      "\n",
      "Epoch #3: train loss=17.58555793762207\n",
      "Epoch #4: validation loss=17.806976318359375\n",
      "\n",
      "Epoch #4: train loss=17.535953521728516\n",
      "Epoch #5: validation loss=17.560094833374023\n",
      "\n",
      "Epoch #5: train loss=17.484237670898438\n",
      "Epoch #6: validation loss=17.826210021972656\n",
      "\n",
      "Epoch #6: train loss=17.414249420166016\n",
      "Epoch #7: validation loss=17.420270919799805\n",
      "\n",
      "Epoch #7: train loss=17.33850860595703\n",
      "Epoch #8: validation loss=17.34860610961914\n",
      "\n",
      "Epoch #8: train loss=17.2409725189209\n",
      "Epoch #9: validation loss=17.15634536743164\n",
      "\n",
      "Epoch #9: train loss=17.18472671508789\n",
      "Epoch #10: validation loss=17.230012893676758\n",
      "\n",
      "Epoch #10: train loss=17.0809268951416\n",
      "Epoch #11: validation loss=17.014469146728516\n",
      "\n",
      "Epoch #11: train loss=16.98137664794922\n",
      "Epoch #12: validation loss=16.992862701416016\n",
      "\n",
      "Epoch #12: train loss=16.750341415405273\n",
      "Epoch #13: validation loss=16.75238800048828\n",
      "\n",
      "Epoch #13: train loss=16.585697174072266\n",
      "Epoch #14: validation loss=16.85943603515625\n",
      "\n",
      "Epoch #14: train loss=16.613317489624023\n",
      "Epoch #15: validation loss=16.627685546875\n",
      "\n",
      "Epoch #15: train loss=16.535533905029297\n",
      "Epoch #16: validation loss=16.537811279296875\n",
      "\n",
      "Epoch #16: train loss=16.4857120513916\n",
      "Epoch #17: validation loss=16.650184631347656\n",
      "\n",
      "Epoch #17: train loss=16.515525817871094\n",
      "Epoch #18: validation loss=16.609636306762695\n",
      "\n",
      "Epoch #18: train loss=16.390195846557617\n",
      "Epoch #19: validation loss=16.320377349853516\n",
      "\n",
      "Epoch #19: train loss=16.433229446411133\n",
      "Epoch #20: validation loss=16.318782806396484\n",
      "\n",
      "Epoch #20: train loss=16.33144760131836\n",
      "Epoch #21: validation loss=16.56195068359375\n",
      "\n",
      "Epoch #21: train loss=16.193531036376953\n",
      "Epoch #22: validation loss=16.38248062133789\n",
      "\n",
      "Epoch #22: train loss=16.264493942260742\n",
      "Epoch #23: validation loss=16.3825626373291\n",
      "\n",
      "Epoch #23: train loss=16.22566032409668\n",
      "Epoch #24: validation loss=16.334136962890625\n",
      "\n",
      "Epoch #24: train loss=16.22338104248047\n",
      "Epoch #25: validation loss=16.217424392700195\n",
      "\n",
      "Epoch #25: train loss=16.326480865478516\n",
      "Epoch #26: validation loss=16.177766799926758\n",
      "\n",
      "Epoch #26: train loss=16.171552658081055\n",
      "Epoch #27: validation loss=16.23271369934082\n",
      "\n",
      "Epoch #27: train loss=16.15172004699707\n",
      "Epoch #28: validation loss=16.403919219970703\n",
      "\n",
      "Epoch #28: train loss=16.2670955657959\n",
      "Epoch #29: validation loss=16.197551727294922\n",
      "\n",
      "Epoch #29: train loss=16.09117889404297\n",
      "Epoch #30: validation loss=16.43621826171875\n",
      "\n",
      "Epoch #30: train loss=16.148134231567383\n",
      "Epoch #31: validation loss=16.14856719970703\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. model = ts_tcc\n",
    "config = config2\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.415004</td>\n",
       "      <td>1.247389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.312446</td>\n",
       "      <td>1.165330</td>\n",
       "      <td>1.543982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.327649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852361</td>\n",
       "      <td>1.548516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.025096</td>\n",
       "      <td>0.184164</td>\n",
       "      <td>1.279742</td>\n",
       "      <td>0.438212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.433192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.408585</td>\n",
       "      <td>1.221739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.291749</td>\n",
       "      <td>1.155547</td>\n",
       "      <td>1.512117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333663</td>\n",
       "      <td>1.335803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842610</td>\n",
       "      <td>1.529925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.009972</td>\n",
       "      <td>0.181050</td>\n",
       "      <td>1.278370</td>\n",
       "      <td>0.388566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.435636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.408841</td>\n",
       "      <td>1.210168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.291822</td>\n",
       "      <td>1.138199</td>\n",
       "      <td>1.512824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.304309</td>\n",
       "      <td>1.330241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850899</td>\n",
       "      <td>1.531653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.010880</td>\n",
       "      <td>0.162559</td>\n",
       "      <td>1.278116</td>\n",
       "      <td>0.384694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.410115</td>\n",
       "      <td>1.190142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.291264</td>\n",
       "      <td>1.143094</td>\n",
       "      <td>1.502158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.312961</td>\n",
       "      <td>1.360146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851072</td>\n",
       "      <td>1.532606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.991898</td>\n",
       "      <td>0.166120</td>\n",
       "      <td>1.278798</td>\n",
       "      <td>0.371485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.407546</td>\n",
       "      <td>1.192116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280644</td>\n",
       "      <td>1.142739</td>\n",
       "      <td>1.496653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.327218</td>\n",
       "      <td>1.347511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848754</td>\n",
       "      <td>1.534866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.993783</td>\n",
       "      <td>0.186403</td>\n",
       "      <td>1.279452</td>\n",
       "      <td>0.369416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.434836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2   V3        V4        V5        V6   V7   V8        V9  \\\n",
       "0  1.415004  1.247389  0.0  1.312446  1.165330  1.543982  0.0  0.0  1.319170   \n",
       "1  1.408585  1.221739  0.0  1.291749  1.155547  1.512117  0.0  0.0  1.333663   \n",
       "2  1.408841  1.210168  0.0  1.291822  1.138199  1.512824  0.0  0.0  1.304309   \n",
       "3  1.410115  1.190142  0.0  1.291264  1.143094  1.502158  0.0  0.0  1.312961   \n",
       "4  1.407546  1.192116  0.0  1.280644  1.142739  1.496653  0.0  0.0  1.327218   \n",
       "\n",
       "        V10  ...  V55       V56       V57  V58       V59       V60       V61  \\\n",
       "0  1.327649  ...  0.0  0.852361  1.548516  0.0  2.025096  0.184164  1.279742   \n",
       "1  1.335803  ...  0.0  0.842610  1.529925  0.0  2.009972  0.181050  1.278370   \n",
       "2  1.330241  ...  0.0  0.850899  1.531653  0.0  2.010880  0.162559  1.278116   \n",
       "3  1.360146  ...  0.0  0.851072  1.532606  0.0  1.991898  0.166120  1.278798   \n",
       "4  1.347511  ...  0.0  0.848754  1.534866  0.0  1.993783  0.186403  1.279452   \n",
       "\n",
       "        V62  V63       V64  \n",
       "0  0.438212  0.0  1.433192  \n",
       "1  0.388566  0.0  1.435636  \n",
       "2  0.384694  0.0  1.431300  \n",
       "3  0.371485  0.0  1.444807  \n",
       "4  0.369416  0.0  1.434836  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.411522</td>\n",
       "      <td>1.319475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.135064</td>\n",
       "      <td>1.163418</td>\n",
       "      <td>1.659809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334034</td>\n",
       "      <td>1.314916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823418</td>\n",
       "      <td>1.663288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.030751</td>\n",
       "      <td>0.186801</td>\n",
       "      <td>1.265284</td>\n",
       "      <td>0.607910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.422119</td>\n",
       "      <td>1.260183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280201</td>\n",
       "      <td>1.081639</td>\n",
       "      <td>1.498350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.300243</td>\n",
       "      <td>1.384459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>1.501606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.962393</td>\n",
       "      <td>0.125497</td>\n",
       "      <td>1.250816</td>\n",
       "      <td>0.395119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.466509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.422595</td>\n",
       "      <td>1.165883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.201591</td>\n",
       "      <td>1.091853</td>\n",
       "      <td>1.469469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.284778</td>\n",
       "      <td>1.396889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833513</td>\n",
       "      <td>1.522691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.925355</td>\n",
       "      <td>0.144013</td>\n",
       "      <td>1.242125</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.459934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.422809</td>\n",
       "      <td>1.175616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227591</td>\n",
       "      <td>1.084457</td>\n",
       "      <td>1.476916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.292325</td>\n",
       "      <td>1.375789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829558</td>\n",
       "      <td>1.529028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.948569</td>\n",
       "      <td>0.120967</td>\n",
       "      <td>1.240961</td>\n",
       "      <td>0.334961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.466668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.426434</td>\n",
       "      <td>1.160866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.207253</td>\n",
       "      <td>1.103280</td>\n",
       "      <td>1.468346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.298864</td>\n",
       "      <td>1.397364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841721</td>\n",
       "      <td>1.525189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923682</td>\n",
       "      <td>0.150940</td>\n",
       "      <td>1.248361</td>\n",
       "      <td>0.319965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.476749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2   V3        V4        V5        V6   V7   V8        V9  \\\n",
       "0  1.411522  1.319475  0.0  1.135064  1.163418  1.659809  0.0  0.0  1.334034   \n",
       "1  1.422119  1.260183  0.0  1.280201  1.081639  1.498350  0.0  0.0  1.300243   \n",
       "2  1.422595  1.165883  0.0  1.201591  1.091853  1.469469  0.0  0.0  1.284778   \n",
       "3  1.422809  1.175616  0.0  1.227591  1.084457  1.476916  0.0  0.0  1.292325   \n",
       "4  1.426434  1.160866  0.0  1.207253  1.103280  1.468346  0.0  0.0  1.298864   \n",
       "\n",
       "        V10  ...  V55       V56       V57  V58       V59       V60       V61  \\\n",
       "0  1.314916  ...  0.0  0.823418  1.663288  0.0  2.030751  0.186801  1.265284   \n",
       "1  1.384459  ...  0.0  0.839122  1.501606  0.0  1.962393  0.125497  1.250816   \n",
       "2  1.396889  ...  0.0  0.833513  1.522691  0.0  1.925355  0.144013  1.242125   \n",
       "3  1.375789  ...  0.0  0.829558  1.529028  0.0  1.948569  0.120967  1.240961   \n",
       "4  1.397364  ...  0.0  0.841721  1.525189  0.0  1.923682  0.150940  1.248361   \n",
       "\n",
       "        V62  V63       V64  \n",
       "0  0.607910  0.0  1.483165  \n",
       "1  0.395119  0.0  1.466509  \n",
       "2  0.309935  0.0  1.459934  \n",
       "3  0.334961  0.0  1.466668  \n",
       "4  0.319965  0.0  1.476749  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=0.3251935541629791\n",
      "Epoch #1: validation loss=0.15816469490528107\n",
      "\n",
      "Epoch #2: train loss=0.305441677570343\n",
      "Epoch #2: validation loss=0.1445966213941574\n",
      "\n",
      "Epoch #3: train loss=0.28639599680900574\n",
      "Epoch #3: validation loss=0.13168644905090332\n",
      "\n",
      "Epoch #4: train loss=0.2673955261707306\n",
      "Epoch #4: validation loss=0.11976871639490128\n",
      "\n",
      "Epoch #5: train loss=0.248679518699646\n",
      "Epoch #5: validation loss=0.10822036862373352\n",
      "\n",
      "Epoch #6: train loss=0.2331651747226715\n",
      "Epoch #6: validation loss=0.10381440818309784\n",
      "\n",
      "Epoch #7: train loss=0.22279992699623108\n",
      "Epoch #7: validation loss=0.10327749699354172\n",
      "\n",
      "Epoch #8: train loss=0.2128724753856659\n",
      "Epoch #8: validation loss=0.10261518508195877\n",
      "\n",
      "Epoch #9: train loss=0.20037129521369934\n",
      "Epoch #9: validation loss=0.10228367149829865\n",
      "\n",
      "Epoch #10: train loss=0.19005003571510315\n",
      "Epoch #10: validation loss=0.09972216188907623\n",
      "\n",
      "Epoch #11: train loss=0.1844574213027954\n",
      "Epoch #11: validation loss=0.09715581685304642\n",
      "\n",
      "Epoch #12: train loss=0.17776505649089813\n",
      "Epoch #12: validation loss=0.09207823872566223\n",
      "\n",
      "Epoch #13: train loss=0.16784285008907318\n",
      "Epoch #13: validation loss=0.08486217260360718\n",
      "\n",
      "Epoch #14: train loss=0.1576482057571411\n",
      "Epoch #14: validation loss=0.07852407544851303\n",
      "\n",
      "Epoch #15: train loss=0.1488541215658188\n",
      "Epoch #15: validation loss=0.07364321500062943\n",
      "\n",
      "Epoch #16: train loss=0.1417858600616455\n",
      "Epoch #16: validation loss=0.07013778388500214\n",
      "\n",
      "Epoch #17: train loss=0.136975958943367\n",
      "Epoch #17: validation loss=0.06853355467319489\n",
      "\n",
      "Epoch #18: train loss=0.13292136788368225\n",
      "Epoch #18: validation loss=0.06682638078927994\n",
      "\n",
      "Epoch #19: train loss=0.13024850189685822\n",
      "Epoch #19: validation loss=0.06610386073589325\n",
      "\n",
      "Epoch #20: train loss=0.1286814659833908\n",
      "Epoch #20: validation loss=0.0650671124458313\n",
      "\n",
      "Epoch #21: train loss=0.1273818016052246\n",
      "Epoch #21: validation loss=0.06468665599822998\n",
      "\n",
      "Epoch #22: train loss=0.12619248032569885\n",
      "Epoch #22: validation loss=0.06393425911664963\n",
      "\n",
      "Epoch #23: train loss=0.12510068714618683\n",
      "Epoch #23: validation loss=0.06296886503696442\n",
      "\n",
      "Epoch #24: train loss=0.1233905479311943\n",
      "Epoch #24: validation loss=0.06206385791301727\n",
      "\n",
      "Epoch #25: train loss=0.12125124782323837\n",
      "Epoch #25: validation loss=0.06017026677727699\n",
      "\n",
      "Epoch #26: train loss=0.11878643184900284\n",
      "Epoch #26: validation loss=0.05825485661625862\n",
      "\n",
      "Epoch #27: train loss=0.1162610650062561\n",
      "Epoch #27: validation loss=0.05696284770965576\n",
      "\n",
      "Epoch #28: train loss=0.11485201120376587\n",
      "Epoch #28: validation loss=0.056244511157274246\n",
      "\n",
      "Epoch #29: train loss=0.11331228166818619\n",
      "Epoch #29: validation loss=0.055436599999666214\n",
      "\n",
      "Epoch #30: train loss=0.11241469532251358\n",
      "Epoch #30: validation loss=0.05477028340101242\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. model = rae_mepc\n",
    "config = config3\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067811</td>\n",
       "      <td>0.630309</td>\n",
       "      <td>0.678385</td>\n",
       "      <td>-0.224692</td>\n",
       "      <td>-0.494843</td>\n",
       "      <td>-0.082273</td>\n",
       "      <td>-0.337692</td>\n",
       "      <td>-0.141722</td>\n",
       "      <td>-0.223741</td>\n",
       "      <td>1.456698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304692</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>-0.365004</td>\n",
       "      <td>-0.390378</td>\n",
       "      <td>-0.368446</td>\n",
       "      <td>0.667603</td>\n",
       "      <td>0.164786</td>\n",
       "      <td>-0.119798</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>0.217439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072153</td>\n",
       "      <td>0.630751</td>\n",
       "      <td>0.686749</td>\n",
       "      <td>-0.223636</td>\n",
       "      <td>-0.507986</td>\n",
       "      <td>-0.094064</td>\n",
       "      <td>-0.350572</td>\n",
       "      <td>-0.141803</td>\n",
       "      <td>-0.219542</td>\n",
       "      <td>1.452028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300298</td>\n",
       "      <td>-0.020464</td>\n",
       "      <td>-0.360855</td>\n",
       "      <td>-0.393285</td>\n",
       "      <td>-0.382104</td>\n",
       "      <td>0.660885</td>\n",
       "      <td>0.158050</td>\n",
       "      <td>-0.120539</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>0.227818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072153</td>\n",
       "      <td>0.638612</td>\n",
       "      <td>0.686749</td>\n",
       "      <td>-0.223636</td>\n",
       "      <td>-0.509670</td>\n",
       "      <td>-0.094064</td>\n",
       "      <td>-0.350733</td>\n",
       "      <td>-0.141803</td>\n",
       "      <td>-0.219542</td>\n",
       "      <td>1.452028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300298</td>\n",
       "      <td>-0.007431</td>\n",
       "      <td>-0.357887</td>\n",
       "      <td>-0.395162</td>\n",
       "      <td>-0.381343</td>\n",
       "      <td>0.669121</td>\n",
       "      <td>0.157673</td>\n",
       "      <td>-0.120539</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>0.227818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062448</td>\n",
       "      <td>0.638658</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>-0.224589</td>\n",
       "      <td>-0.515836</td>\n",
       "      <td>-0.098094</td>\n",
       "      <td>-0.362724</td>\n",
       "      <td>-0.149598</td>\n",
       "      <td>-0.215638</td>\n",
       "      <td>1.437033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310291</td>\n",
       "      <td>-0.007431</td>\n",
       "      <td>-0.355633</td>\n",
       "      <td>-0.395879</td>\n",
       "      <td>-0.381343</td>\n",
       "      <td>0.670142</td>\n",
       "      <td>0.158143</td>\n",
       "      <td>-0.138508</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>0.214453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064106</td>\n",
       "      <td>0.640889</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>-0.226771</td>\n",
       "      <td>-0.515336</td>\n",
       "      <td>-0.089185</td>\n",
       "      <td>-0.353286</td>\n",
       "      <td>-0.138173</td>\n",
       "      <td>-0.211655</td>\n",
       "      <td>1.447111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310015</td>\n",
       "      <td>-0.006760</td>\n",
       "      <td>-0.355429</td>\n",
       "      <td>-0.398926</td>\n",
       "      <td>-0.381573</td>\n",
       "      <td>0.671615</td>\n",
       "      <td>0.158277</td>\n",
       "      <td>-0.128860</td>\n",
       "      <td>0.022683</td>\n",
       "      <td>0.219661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.067811  0.630309  0.678385 -0.224692 -0.494843 -0.082273 -0.337692   \n",
       "1  0.072153  0.630751  0.686749 -0.223636 -0.507986 -0.094064 -0.350572   \n",
       "2  0.072153  0.638612  0.686749 -0.223636 -0.509670 -0.094064 -0.350733   \n",
       "3  0.062448  0.638658  0.674399 -0.224589 -0.515836 -0.098094 -0.362724   \n",
       "4  0.064106  0.640889  0.685494 -0.226771 -0.515336 -0.089185 -0.353286   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.141722 -0.223741  1.456698  ... -0.304692 -0.011693 -0.365004 -0.390378   \n",
       "1 -0.141803 -0.219542  1.452028  ... -0.300298 -0.020464 -0.360855 -0.393285   \n",
       "2 -0.141803 -0.219542  1.452028  ... -0.300298 -0.007431 -0.357887 -0.395162   \n",
       "3 -0.149598 -0.215638  1.437033  ... -0.310291 -0.007431 -0.355633 -0.395879   \n",
       "4 -0.138173 -0.211655  1.447111  ... -0.310015 -0.006760 -0.355429 -0.398926   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.368446  0.667603  0.164786 -0.119798  0.028371  0.217439  \n",
       "1 -0.382104  0.660885  0.158050 -0.120539  0.032266  0.227818  \n",
       "2 -0.381343  0.669121  0.157673 -0.120539  0.032266  0.227818  \n",
       "3 -0.381343  0.670142  0.158143 -0.138508  0.017491  0.214453  \n",
       "4 -0.381573  0.671615  0.158277 -0.128860  0.022683  0.219661  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.574629</td>\n",
       "      <td>0.770907</td>\n",
       "      <td>-0.245455</td>\n",
       "      <td>-0.387932</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>-0.301693</td>\n",
       "      <td>-0.052747</td>\n",
       "      <td>-0.156665</td>\n",
       "      <td>1.473217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303291</td>\n",
       "      <td>-0.076165</td>\n",
       "      <td>-0.333392</td>\n",
       "      <td>-0.430074</td>\n",
       "      <td>-0.289225</td>\n",
       "      <td>0.759626</td>\n",
       "      <td>0.182444</td>\n",
       "      <td>-0.070789</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.244707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.623049</td>\n",
       "      <td>0.738260</td>\n",
       "      <td>-0.245455</td>\n",
       "      <td>-0.438132</td>\n",
       "      <td>-0.072092</td>\n",
       "      <td>-0.335119</td>\n",
       "      <td>-0.116647</td>\n",
       "      <td>-0.212243</td>\n",
       "      <td>1.453629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303291</td>\n",
       "      <td>-0.012675</td>\n",
       "      <td>-0.338566</td>\n",
       "      <td>-0.425654</td>\n",
       "      <td>-0.342676</td>\n",
       "      <td>0.718123</td>\n",
       "      <td>0.170675</td>\n",
       "      <td>-0.089175</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.244707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089741</td>\n",
       "      <td>0.623049</td>\n",
       "      <td>0.697248</td>\n",
       "      <td>-0.248375</td>\n",
       "      <td>-0.460601</td>\n",
       "      <td>-0.099862</td>\n",
       "      <td>-0.367788</td>\n",
       "      <td>-0.153542</td>\n",
       "      <td>-0.221222</td>\n",
       "      <td>1.424201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322693</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>-0.332708</td>\n",
       "      <td>-0.423858</td>\n",
       "      <td>-0.341373</td>\n",
       "      <td>0.729697</td>\n",
       "      <td>0.173032</td>\n",
       "      <td>-0.118748</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>0.203656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089741</td>\n",
       "      <td>0.629642</td>\n",
       "      <td>0.697065</td>\n",
       "      <td>-0.252234</td>\n",
       "      <td>-0.460601</td>\n",
       "      <td>-0.099238</td>\n",
       "      <td>-0.367788</td>\n",
       "      <td>-0.153542</td>\n",
       "      <td>-0.209767</td>\n",
       "      <td>1.424201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329457</td>\n",
       "      <td>0.026987</td>\n",
       "      <td>-0.321140</td>\n",
       "      <td>-0.422830</td>\n",
       "      <td>-0.337990</td>\n",
       "      <td>0.745214</td>\n",
       "      <td>0.174257</td>\n",
       "      <td>-0.118748</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>0.194724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064320</td>\n",
       "      <td>0.629642</td>\n",
       "      <td>0.704274</td>\n",
       "      <td>-0.252234</td>\n",
       "      <td>-0.480357</td>\n",
       "      <td>-0.080069</td>\n",
       "      <td>-0.369631</td>\n",
       "      <td>-0.133919</td>\n",
       "      <td>-0.194449</td>\n",
       "      <td>1.420977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346233</td>\n",
       "      <td>0.026987</td>\n",
       "      <td>-0.320160</td>\n",
       "      <td>-0.422830</td>\n",
       "      <td>-0.337990</td>\n",
       "      <td>0.745214</td>\n",
       "      <td>0.174257</td>\n",
       "      <td>-0.137089</td>\n",
       "      <td>-0.038669</td>\n",
       "      <td>0.175696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.111111  0.574629  0.770907 -0.245455 -0.387932 -0.004334 -0.301693   \n",
       "1  0.109244  0.623049  0.738260 -0.245455 -0.438132 -0.072092 -0.335119   \n",
       "2  0.089741  0.623049  0.697248 -0.248375 -0.460601 -0.099862 -0.367788   \n",
       "3  0.089741  0.629642  0.697065 -0.252234 -0.460601 -0.099238 -0.367788   \n",
       "4  0.064320  0.629642  0.704274 -0.252234 -0.480357 -0.080069 -0.369631   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.052747 -0.156665  1.473217  ... -0.303291 -0.076165 -0.333392 -0.430074   \n",
       "1 -0.116647 -0.212243  1.453629  ... -0.303291 -0.012675 -0.338566 -0.425654   \n",
       "2 -0.153542 -0.221222  1.424201  ... -0.322693 -0.001682 -0.332708 -0.423858   \n",
       "3 -0.153542 -0.209767  1.424201  ... -0.329457  0.026987 -0.321140 -0.422830   \n",
       "4 -0.133919 -0.194449  1.420977  ... -0.346233  0.026987 -0.320160 -0.422830   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.289225  0.759626  0.182444 -0.070789  0.011681  0.244707  \n",
       "1 -0.342676  0.718123  0.170675 -0.089175  0.011681  0.244707  \n",
       "2 -0.341373  0.729697  0.173032 -0.118748 -0.014104  0.203656  \n",
       "3 -0.337990  0.745214  0.174257 -0.118748 -0.016303  0.194724  \n",
       "4 -0.337990  0.745214  0.174257 -0.137089 -0.038669  0.175696  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: loss=2.0070038635064575\n",
      "Epoch #1: validation loss=0.11913683079183102\n",
      "\n",
      "Epoch #2: loss=0.10930594363633324\n",
      "Epoch #2: validation loss=0.10193572379648685\n",
      "\n",
      "Epoch #3: loss=0.10185562030357473\n",
      "Epoch #3: validation loss=0.09928877651691437\n",
      "\n",
      "Epoch #4: loss=0.10030568084296058\n",
      "Epoch #4: validation loss=0.09756442345678806\n",
      "\n",
      "Epoch #5: loss=0.0994102889124085\n",
      "Epoch #5: validation loss=0.09733622893691063\n",
      "\n",
      "Epoch #6: loss=0.09906453902230543\n",
      "Epoch #6: validation loss=0.09697526507079601\n",
      "\n",
      "Epoch #7: loss=0.09919325087000341\n",
      "Epoch #7: validation loss=0.09693634137511253\n",
      "\n",
      "Epoch #8: loss=0.09855554647305433\n",
      "Epoch #8: validation loss=0.0967323575168848\n",
      "\n",
      "Epoch #9: loss=0.0968994230908506\n",
      "Epoch #9: validation loss=0.09242820739746094\n",
      "\n",
      "Epoch #10: loss=0.09095856635009542\n",
      "Epoch #10: validation loss=0.08500596322119236\n",
      "\n",
      "Epoch #11: loss=0.08550137894995072\n",
      "Epoch #11: validation loss=0.08121322467923164\n",
      "\n",
      "Epoch #12: loss=0.08093429751255933\n",
      "Epoch #12: validation loss=0.07434214279055595\n",
      "\n",
      "Epoch #13: loss=0.0724239130230511\n",
      "Epoch #13: validation loss=0.06552508287131786\n",
      "\n",
      "Epoch #14: loss=0.06534243024447385\n",
      "Epoch #14: validation loss=0.06163675989955664\n",
      "\n",
      "Epoch #15: loss=0.06200737111708697\n",
      "Epoch #15: validation loss=0.05826496984809637\n",
      "\n",
      "Epoch #16: loss=0.06003061199889464\n",
      "Epoch #16: validation loss=0.05719533655792475\n",
      "\n",
      "Epoch #17: loss=0.059182302697616464\n",
      "Epoch #17: validation loss=0.05649768002331257\n",
      "\n",
      "Epoch #18: loss=0.05898494185770259\n",
      "Epoch #18: validation loss=0.05653270613402128\n",
      "\n",
      "Epoch #19: loss=0.058808288591749525\n",
      "Epoch #19: validation loss=0.055498973466455936\n",
      "\n",
      "Epoch #20: loss=0.05821064640493954\n",
      "Epoch #20: validation loss=0.05471916403621435\n",
      "\n",
      "Epoch #21: loss=0.0567474468227695\n",
      "Epoch #21: validation loss=0.052331218495965004\n",
      "\n",
      "Epoch #22: loss=0.05393278138602481\n",
      "Epoch #22: validation loss=0.04977444652467966\n",
      "\n",
      "Epoch #23: loss=0.05068065138424144\n",
      "Epoch #23: validation loss=0.04643123783171177\n",
      "\n",
      "Epoch #24: loss=0.04696571366751895\n",
      "Epoch #24: validation loss=0.04152125772088766\n",
      "\n",
      "Epoch #25: loss=0.04189143811955171\n",
      "Epoch #25: validation loss=0.037328305654227734\n",
      "\n",
      "Epoch #26: loss=0.03830376815269975\n",
      "Epoch #26: validation loss=0.034750587306916714\n",
      "\n",
      "Epoch #27: loss=0.03642807572203524\n",
      "Epoch #27: validation loss=0.03401481080800295\n",
      "\n",
      "Epoch #28: loss=0.03573345414855901\n",
      "Epoch #28: validation loss=0.033487025648355484\n",
      "\n",
      "Epoch #29: loss=0.035378498627859\n",
      "Epoch #29: validation loss=0.03341040201485157\n",
      "\n",
      "Epoch #30: loss=0.03540836154099773\n",
      "Epoch #30: validation loss=0.03300233464688063\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. model = stoc\n",
    "config = config4\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.398952</td>\n",
       "      <td>0.290622</td>\n",
       "      <td>0.324225</td>\n",
       "      <td>-0.394981</td>\n",
       "      <td>-0.437825</td>\n",
       "      <td>0.208608</td>\n",
       "      <td>-1.034431</td>\n",
       "      <td>-0.938719</td>\n",
       "      <td>-0.908528</td>\n",
       "      <td>1.510468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377648</td>\n",
       "      <td>0.242635</td>\n",
       "      <td>0.436007</td>\n",
       "      <td>-0.819171</td>\n",
       "      <td>-0.615345</td>\n",
       "      <td>0.205519</td>\n",
       "      <td>-0.008637</td>\n",
       "      <td>-0.024010</td>\n",
       "      <td>-0.719357</td>\n",
       "      <td>0.465744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.398952</td>\n",
       "      <td>0.284166</td>\n",
       "      <td>0.324225</td>\n",
       "      <td>-0.394981</td>\n",
       "      <td>-0.438264</td>\n",
       "      <td>0.208608</td>\n",
       "      <td>-1.034431</td>\n",
       "      <td>-0.938719</td>\n",
       "      <td>-0.908528</td>\n",
       "      <td>1.499745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376878</td>\n",
       "      <td>0.242635</td>\n",
       "      <td>0.431513</td>\n",
       "      <td>-0.818394</td>\n",
       "      <td>-0.614960</td>\n",
       "      <td>0.199832</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>-0.024010</td>\n",
       "      <td>-0.719357</td>\n",
       "      <td>0.465744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.387353</td>\n",
       "      <td>0.284166</td>\n",
       "      <td>0.340648</td>\n",
       "      <td>-0.377317</td>\n",
       "      <td>-0.436637</td>\n",
       "      <td>0.212478</td>\n",
       "      <td>-1.032836</td>\n",
       "      <td>-0.931129</td>\n",
       "      <td>-0.905558</td>\n",
       "      <td>1.496878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376878</td>\n",
       "      <td>0.255813</td>\n",
       "      <td>0.431513</td>\n",
       "      <td>-0.817827</td>\n",
       "      <td>-0.614960</td>\n",
       "      <td>0.199832</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>-0.016742</td>\n",
       "      <td>-0.714316</td>\n",
       "      <td>0.474150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.387353</td>\n",
       "      <td>0.276282</td>\n",
       "      <td>0.340648</td>\n",
       "      <td>-0.377317</td>\n",
       "      <td>-0.433730</td>\n",
       "      <td>0.214189</td>\n",
       "      <td>-1.032836</td>\n",
       "      <td>-0.931129</td>\n",
       "      <td>-0.905558</td>\n",
       "      <td>1.475613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377878</td>\n",
       "      <td>0.261039</td>\n",
       "      <td>0.430023</td>\n",
       "      <td>-0.815575</td>\n",
       "      <td>-0.615355</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>-0.015549</td>\n",
       "      <td>-0.014781</td>\n",
       "      <td>-0.714316</td>\n",
       "      <td>0.474150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.389302</td>\n",
       "      <td>0.276282</td>\n",
       "      <td>0.332543</td>\n",
       "      <td>-0.380108</td>\n",
       "      <td>-0.433650</td>\n",
       "      <td>0.214189</td>\n",
       "      <td>-1.032949</td>\n",
       "      <td>-0.937065</td>\n",
       "      <td>-0.906430</td>\n",
       "      <td>1.484461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380463</td>\n",
       "      <td>0.261039</td>\n",
       "      <td>0.430023</td>\n",
       "      <td>-0.815529</td>\n",
       "      <td>-0.615725</td>\n",
       "      <td>0.179552</td>\n",
       "      <td>-0.015549</td>\n",
       "      <td>-0.013870</td>\n",
       "      <td>-0.719365</td>\n",
       "      <td>0.470728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.398952  0.290622  0.324225 -0.394981 -0.437825  0.208608 -1.034431   \n",
       "1 -0.398952  0.284166  0.324225 -0.394981 -0.438264  0.208608 -1.034431   \n",
       "2 -0.387353  0.284166  0.340648 -0.377317 -0.436637  0.212478 -1.032836   \n",
       "3 -0.387353  0.276282  0.340648 -0.377317 -0.433730  0.214189 -1.032836   \n",
       "4 -0.389302  0.276282  0.332543 -0.380108 -0.433650  0.214189 -1.032949   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.938719 -0.908528  1.510468  ... -0.377648  0.242635  0.436007 -0.819171   \n",
       "1 -0.938719 -0.908528  1.499745  ... -0.376878  0.242635  0.431513 -0.818394   \n",
       "2 -0.931129 -0.905558  1.496878  ... -0.376878  0.255813  0.431513 -0.817827   \n",
       "3 -0.931129 -0.905558  1.475613  ... -0.377878  0.261039  0.430023 -0.815575   \n",
       "4 -0.937065 -0.906430  1.484461  ... -0.380463  0.261039  0.430023 -0.815529   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.615345  0.205519 -0.008637 -0.024010 -0.719357  0.465744  \n",
       "1 -0.614960  0.199832 -0.006871 -0.024010 -0.719357  0.465744  \n",
       "2 -0.614960  0.199832 -0.006871 -0.016742 -0.714316  0.474150  \n",
       "3 -0.615355  0.177819 -0.015549 -0.014781 -0.714316  0.474150  \n",
       "4 -0.615725  0.179552 -0.015549 -0.013870 -0.719365  0.470728  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.421725</td>\n",
       "      <td>0.429874</td>\n",
       "      <td>0.205252</td>\n",
       "      <td>-0.420332</td>\n",
       "      <td>-0.391113</td>\n",
       "      <td>0.205659</td>\n",
       "      <td>-1.018567</td>\n",
       "      <td>-0.995579</td>\n",
       "      <td>-0.906346</td>\n",
       "      <td>1.724268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401557</td>\n",
       "      <td>0.238907</td>\n",
       "      <td>0.554475</td>\n",
       "      <td>-0.764480</td>\n",
       "      <td>-0.611959</td>\n",
       "      <td>0.300524</td>\n",
       "      <td>0.028026</td>\n",
       "      <td>-0.011310</td>\n",
       "      <td>-0.761547</td>\n",
       "      <td>0.408547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.389708</td>\n",
       "      <td>0.415705</td>\n",
       "      <td>0.286972</td>\n",
       "      <td>-0.376126</td>\n",
       "      <td>-0.393209</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>-1.018567</td>\n",
       "      <td>-0.968899</td>\n",
       "      <td>-0.901835</td>\n",
       "      <td>1.566057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400865</td>\n",
       "      <td>0.280335</td>\n",
       "      <td>0.504924</td>\n",
       "      <td>-0.764480</td>\n",
       "      <td>-0.611959</td>\n",
       "      <td>0.300524</td>\n",
       "      <td>0.028026</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>-0.740072</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.389708</td>\n",
       "      <td>0.343615</td>\n",
       "      <td>0.286972</td>\n",
       "      <td>-0.373838</td>\n",
       "      <td>-0.399181</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>-1.020280</td>\n",
       "      <td>-0.968899</td>\n",
       "      <td>-0.901835</td>\n",
       "      <td>1.509274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400865</td>\n",
       "      <td>0.281210</td>\n",
       "      <td>0.471867</td>\n",
       "      <td>-0.786482</td>\n",
       "      <td>-0.617629</td>\n",
       "      <td>0.221537</td>\n",
       "      <td>-0.003782</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>-0.740072</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.372006</td>\n",
       "      <td>0.343615</td>\n",
       "      <td>0.300817</td>\n",
       "      <td>-0.349442</td>\n",
       "      <td>-0.399181</td>\n",
       "      <td>0.225255</td>\n",
       "      <td>-1.014195</td>\n",
       "      <td>-0.959147</td>\n",
       "      <td>-0.894597</td>\n",
       "      <td>1.509274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402881</td>\n",
       "      <td>0.306219</td>\n",
       "      <td>0.471867</td>\n",
       "      <td>-0.785659</td>\n",
       "      <td>-0.615510</td>\n",
       "      <td>0.221537</td>\n",
       "      <td>-0.003782</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>-0.737734</td>\n",
       "      <td>0.450091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.372006</td>\n",
       "      <td>0.317695</td>\n",
       "      <td>0.300817</td>\n",
       "      <td>-0.349442</td>\n",
       "      <td>-0.398042</td>\n",
       "      <td>0.225255</td>\n",
       "      <td>-1.013953</td>\n",
       "      <td>-0.959147</td>\n",
       "      <td>-0.894597</td>\n",
       "      <td>1.468945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402881</td>\n",
       "      <td>0.306219</td>\n",
       "      <td>0.469023</td>\n",
       "      <td>-0.781360</td>\n",
       "      <td>-0.615510</td>\n",
       "      <td>0.173415</td>\n",
       "      <td>-0.018760</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>-0.737734</td>\n",
       "      <td>0.450091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.421725  0.429874  0.205252 -0.420332 -0.391113  0.205659 -1.018567   \n",
       "1 -0.389708  0.415705  0.286972 -0.376126 -0.393209  0.218218 -1.018567   \n",
       "2 -0.389708  0.343615  0.286972 -0.373838 -0.399181  0.218976 -1.020280   \n",
       "3 -0.372006  0.343615  0.300817 -0.349442 -0.399181  0.225255 -1.014195   \n",
       "4 -0.372006  0.317695  0.300817 -0.349442 -0.398042  0.225255 -1.013953   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.995579 -0.906346  1.724268  ... -0.401557  0.238907  0.554475 -0.764480   \n",
       "1 -0.968899 -0.901835  1.566057  ... -0.400865  0.280335  0.504924 -0.764480   \n",
       "2 -0.968899 -0.901835  1.509274  ... -0.400865  0.281210  0.471867 -0.786482   \n",
       "3 -0.959147 -0.894597  1.509274  ... -0.402881  0.306219  0.471867 -0.785659   \n",
       "4 -0.959147 -0.894597  1.468945  ... -0.402881  0.306219  0.469023 -0.781360   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.611959  0.300524  0.028026 -0.011310 -0.761547  0.408547  \n",
       "1 -0.611959  0.300524  0.028026  0.005134 -0.740072  0.445111  \n",
       "2 -0.617629  0.221537 -0.003782  0.010128 -0.740072  0.445111  \n",
       "3 -0.615510  0.221537 -0.003782  0.016148 -0.737734  0.450091  \n",
       "4 -0.615510  0.173415 -0.018760  0.016148 -0.737734  0.450091  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af2d87a9baae9e19220b6d245f822c980479669c4aad7c3aadfe7a700f0cdbad"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
