{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import main_data_representation as mdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. model = ts2vec\n",
    "config1 = {\n",
    "    \"model\": 'ts2vec',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/ts2vec.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 64,  # encoder의 hidden dimension, int(default: 64, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"num_epochs\": 50,  # 학습 epoch 횟수, int(default: 50, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 2. model = ts_tcc\n",
    "config2 = {\n",
    "    \"model\": 'ts_tcc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/ts_tcc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 100,  # temporal / contextual contrasting 모듈의 hidden dimension, int(default: 100, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"timesteps\": 6,  # temporal contrasting 모듈에서 미래 예측할 시점의 길이, int(default: 6, 범위: 1 이상)\n",
    "        \"num_epochs\": 50,  # 학습 epoch 횟수, int(default: 50, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        \"jitter_scale_ratio\": 1.1,  # time series data augementation 중 weak augementation의 강도, float(default: 1.1, default 값 사용 권장)\n",
    "        \"jitter_ratio\": 0.8,  # time series data augementation 중 strong augementation의 강도, float(default: 0.8, default 값 사용 권장)\n",
    "        \"max_seg\": 8  # strong augementation에서 permutation 진행시 데이터의 최대 분할 개수, int(default: 8, default 값 사용 권장)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 3. model = rae_mepc\n",
    "config3 = {\n",
    "    \"model\": 'rae_mepc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/rae_mepc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": {\n",
    "        \"window_size\": 32,  # 모델의 input sequence 길이, int(default: 32, 범위: 0 이상 & 원래 데이터의 sequence 길이 이하)\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"enc_nlayers\": 3,  # multi-resolution encoder를 구성하는 sub-encoder의 개수, int(default: 3, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"dec_nlayers\": 3,  # multi-resolution decoder를 구성하는 sub-decoder의 개수, int(default: 3, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"tau\": 4,  # multi-resolution encoder 및 decoder의 resolution를 조절하는 값, int(default: 4, 범위: 2 이상, default 값 사용 권장)\n",
    "        \"num_epochs\": 50,  # 학습 epoch 횟수, int(default: 50, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\"  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "    }\n",
    "}\n",
    "\n",
    "# Case 4. model = stoc\n",
    "config4 = {\n",
    "    \"model\": 'stoc',\n",
    "    \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "    \"best_model_path\": './ckpt/stoc.pt',  # 학습 완료 모델 저장 경로\n",
    "    \"parameter\": { \n",
    "        \"window_size\": 32,  # 모델의 input sequence 길이, int(default: 32, 범위: 0 이상 & 원래 데이터의 sequence 길이 이하)\n",
    "        \"input_dim\": 9,  # 데이터의 변수 개수, int\n",
    "        \"repr_dim\": 64,  # data representation 차원, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        \"hidden_dim\": 256,  # encoder의 hidden dimension, int(default: 256, 범위: 1 이상, default 값 사용 권장)\n",
    "        \"forecast_step\": 1,  # 미래 시계열 데이터에 대하여 예측할 시점의 길이, int(default: 6, 범위: 1 이상)\n",
    "        \"num_epochs\": 50,  # 학습 epoch 횟수, int(default: 50, 범위: 1 이상)\n",
    "        \"batch_size\": 512,  # batch 크기, int(default: 512, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "        \"lr\": 0.001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "        \"device\": \"cuda\",  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택, \n",
    "        \"patience\": 10,  # 예측 모델 학습 시, 사전 설정한 epoch 동안 loss가 감소하지 않으면 학습 조기 중단, int(default: 10, 범위: 1 이상 num_epochs 미만)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset_dir = {\n",
    "    \"train\": './data/X_train.pkl',\n",
    "    \"test\": './data/X_test.pkl'\n",
    "}\n",
    "\n",
    "# train/test 데이터 불러오기 (pickle 형태)\n",
    "# shape=(# observations, # features, # time steps)\n",
    "train_data = pickle.load(open(dataset_dir[\"train\"], 'rb'))  # shape=(7352, 9, 128)\n",
    "test_data = pickle.load(open(dataset_dir[\"test\"], 'rb'))  # shape=(2947, 9, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=4.936868476867676\n",
      "Epoch #1: validation loss=4.943576335906982\n",
      "\n",
      "Epoch #2: train loss=4.627585792541504\n",
      "Epoch #2: validation loss=4.884347915649414\n",
      "\n",
      "Epoch #3: train loss=4.79036808013916\n",
      "Epoch #3: validation loss=4.623116493225098\n",
      "\n",
      "Epoch #4: train loss=4.55261926651001\n",
      "Epoch #4: validation loss=4.731514930725098\n",
      "\n",
      "Epoch #5: train loss=4.5294112205505375\n",
      "Epoch #5: validation loss=4.675436973571777\n",
      "\n",
      "Epoch #6: train loss=4.473555088043213\n",
      "Epoch #6: validation loss=4.2629075050354\n",
      "\n",
      "Epoch #7: train loss=4.341904354095459\n",
      "Epoch #7: validation loss=4.463427543640137\n",
      "\n",
      "Epoch #8: train loss=4.481424331665039\n",
      "Epoch #8: validation loss=4.20048189163208\n",
      "\n",
      "Epoch #9: train loss=4.2812458038330075\n",
      "Epoch #9: validation loss=4.146800994873047\n",
      "\n",
      "Epoch #10: train loss=4.198643016815185\n",
      "Epoch #10: validation loss=4.0082621574401855\n",
      "\n",
      "Epoch #11: train loss=4.109360694885254\n",
      "Epoch #11: validation loss=4.026050567626953\n",
      "\n",
      "Epoch #12: train loss=4.023466968536377\n",
      "Epoch #12: validation loss=3.872009515762329\n",
      "\n",
      "Epoch #13: train loss=3.79688982963562\n",
      "Epoch #13: validation loss=3.7302920818328857\n",
      "\n",
      "Epoch #14: train loss=3.729768896102905\n",
      "Epoch #14: validation loss=3.6859381198883057\n",
      "\n",
      "Epoch #15: train loss=3.6393598079681397\n",
      "Epoch #15: validation loss=3.4673187732696533\n",
      "\n",
      "Epoch #16: train loss=3.5942234992980957\n",
      "Epoch #16: validation loss=3.4088637828826904\n",
      "\n",
      "Epoch #17: train loss=3.341631364822388\n",
      "Epoch #17: validation loss=3.2839369773864746\n",
      "\n",
      "Epoch #18: train loss=3.3109140396118164\n",
      "Epoch #18: validation loss=3.188924551010132\n",
      "\n",
      "Epoch #19: train loss=3.100282382965088\n",
      "Epoch #19: validation loss=3.0482640266418457\n",
      "\n",
      "Epoch #20: train loss=3.28807053565979\n",
      "Epoch #20: validation loss=3.06215238571167\n",
      "\n",
      "Epoch #21: train loss=3.142544174194336\n",
      "Epoch #21: validation loss=3.0613369941711426\n",
      "\n",
      "Epoch #22: train loss=3.113007164001465\n",
      "Epoch #22: validation loss=2.90006685256958\n",
      "\n",
      "Epoch #23: train loss=3.0539270401000977\n",
      "Epoch #23: validation loss=2.80207896232605\n",
      "\n",
      "Epoch #24: train loss=3.068688917160034\n",
      "Epoch #24: validation loss=2.8157551288604736\n",
      "\n",
      "Epoch #25: train loss=3.013983631134033\n",
      "Epoch #25: validation loss=2.746485710144043\n",
      "\n",
      "Epoch #26: train loss=2.706918954849243\n",
      "Epoch #26: validation loss=2.614478349685669\n",
      "\n",
      "Epoch #27: train loss=2.6946608543396\n",
      "Epoch #27: validation loss=2.517545700073242\n",
      "\n",
      "Epoch #28: train loss=2.8494277000427246\n",
      "Epoch #28: validation loss=2.881497859954834\n",
      "\n",
      "Epoch #29: train loss=2.681528377532959\n",
      "Epoch #29: validation loss=2.6010406017303467\n",
      "\n",
      "Epoch #30: train loss=2.683120775222778\n",
      "Epoch #30: validation loss=2.4658429622650146\n",
      "\n",
      "Epoch #31: train loss=2.8651238918304442\n",
      "Epoch #31: validation loss=2.3976387977600098\n",
      "\n",
      "Epoch #32: train loss=2.521974515914917\n",
      "Epoch #32: validation loss=2.6555287837982178\n",
      "\n",
      "Epoch #33: train loss=2.389539861679077\n",
      "Epoch #33: validation loss=2.4634652137756348\n",
      "\n",
      "Epoch #34: train loss=2.376496982574463\n",
      "Epoch #34: validation loss=3.3809235095977783\n",
      "\n",
      "Epoch #35: train loss=2.2044751167297365\n",
      "Epoch #35: validation loss=2.077316999435425\n",
      "\n",
      "Epoch #36: train loss=2.2491989135742188\n",
      "Epoch #36: validation loss=2.3115592002868652\n",
      "\n",
      "Epoch #37: train loss=2.242258834838867\n",
      "Epoch #37: validation loss=2.0683064460754395\n",
      "\n",
      "Epoch #38: train loss=2.8145220279693604\n",
      "Epoch #38: validation loss=2.372596025466919\n",
      "\n",
      "Epoch #39: train loss=2.522183561325073\n",
      "Epoch #39: validation loss=2.3079261779785156\n",
      "\n",
      "Epoch #40: train loss=2.313431978225708\n",
      "Epoch #40: validation loss=2.1493287086486816\n",
      "\n",
      "Epoch #41: train loss=2.2939709186553956\n",
      "Epoch #41: validation loss=2.389404296875\n",
      "\n",
      "Epoch #42: train loss=2.3098870754241942\n",
      "Epoch #42: validation loss=2.11533522605896\n",
      "\n",
      "Epoch #43: train loss=2.0782472848892213\n",
      "Epoch #43: validation loss=2.159475803375244\n",
      "\n",
      "Epoch #44: train loss=2.0325757265090942\n",
      "Epoch #44: validation loss=1.9832650423049927\n",
      "\n",
      "Epoch #45: train loss=1.9467760086059571\n",
      "Epoch #45: validation loss=1.8828493356704712\n",
      "\n",
      "Epoch #46: train loss=2.3175305843353273\n",
      "Epoch #46: validation loss=2.9741015434265137\n",
      "\n",
      "Epoch #47: train loss=2.4221006631851196\n",
      "Epoch #47: validation loss=2.2239856719970703\n",
      "\n",
      "Epoch #48: train loss=2.1781945705413817\n",
      "Epoch #48: validation loss=1.8708463907241821\n",
      "\n",
      "Epoch #49: train loss=1.9847445487976074\n",
      "Epoch #49: validation loss=1.8713933229446411\n",
      "\n",
      "Epoch #50: train loss=1.777901816368103\n",
      "Epoch #50: validation loss=1.6608784198760986\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. model = ts2vec\n",
    "config = config1\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013295</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.244010</td>\n",
       "      <td>0.198956</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>1.548550</td>\n",
       "      <td>0.776289</td>\n",
       "      <td>1.434361</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102955</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>1.009223</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.713275</td>\n",
       "      <td>-0.044171</td>\n",
       "      <td>-0.020635</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>-0.035363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.037686</td>\n",
       "      <td>0.244832</td>\n",
       "      <td>0.204868</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>1.535955</td>\n",
       "      <td>0.815045</td>\n",
       "      <td>1.449501</td>\n",
       "      <td>0.118022</td>\n",
       "      <td>-0.032593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>0.024197</td>\n",
       "      <td>0.959976</td>\n",
       "      <td>-0.028372</td>\n",
       "      <td>0.784408</td>\n",
       "      <td>0.092432</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.024973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.215702</td>\n",
       "      <td>0.172657</td>\n",
       "      <td>0.773396</td>\n",
       "      <td>1.599531</td>\n",
       "      <td>0.699918</td>\n",
       "      <td>1.435774</td>\n",
       "      <td>0.227197</td>\n",
       "      <td>0.032223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107260</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.971930</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>-0.018825</td>\n",
       "      <td>0.089505</td>\n",
       "      <td>0.087803</td>\n",
       "      <td>0.028894</td>\n",
       "      <td>0.056081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.048631</td>\n",
       "      <td>-0.103282</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.199997</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>1.619585</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>1.454298</td>\n",
       "      <td>0.192399</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>-0.083185</td>\n",
       "      <td>0.926623</td>\n",
       "      <td>-0.003074</td>\n",
       "      <td>0.845482</td>\n",
       "      <td>-0.151960</td>\n",
       "      <td>0.092022</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>-0.022313</td>\n",
       "      <td>-0.099365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.059146</td>\n",
       "      <td>0.229711</td>\n",
       "      <td>0.199662</td>\n",
       "      <td>0.678738</td>\n",
       "      <td>1.608757</td>\n",
       "      <td>0.743883</td>\n",
       "      <td>1.477629</td>\n",
       "      <td>0.197255</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131444</td>\n",
       "      <td>-0.074090</td>\n",
       "      <td>0.903523</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.879731</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.099931</td>\n",
       "      <td>0.048464</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>-0.068622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.013295  0.028089  0.244010  0.198956  0.722100  1.548550  0.776289   \n",
       "1  0.008384  0.037686  0.244832  0.204868  0.840896  1.535955  0.815045   \n",
       "2  0.073099  0.043213  0.215702  0.172657  0.773396  1.599531  0.699918   \n",
       "3 -0.048631 -0.103282  0.207749  0.199997  0.478100  1.619585  0.700773   \n",
       "4  0.002300  0.059146  0.229711  0.199662  0.678738  1.608757  0.743883   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  1.434361  0.002931 -0.018699  ...  0.102955  0.046750  1.009223  0.061086   \n",
       "1  1.449501  0.118022 -0.032593  ...  0.075448  0.024197  0.959976 -0.028372   \n",
       "2  1.435774  0.227197  0.032223  ...  0.107260  0.040140  0.971930  0.014136   \n",
       "3  1.454298  0.192399  0.000166  ...  0.101328 -0.083185  0.926623 -0.003074   \n",
       "4  1.477629  0.197255  0.070348  ...  0.131444 -0.074090  0.903523  0.016384   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0  0.713275 -0.044171 -0.020635 -0.001691  0.012473 -0.035363  \n",
       "1  0.784408  0.092432  0.082617 -0.013228  0.003990 -0.024973  \n",
       "2  0.747191 -0.018825  0.089505  0.087803  0.028894  0.056081  \n",
       "3  0.845482 -0.151960  0.092022  0.073950 -0.022313 -0.099365  \n",
       "4  0.879731  0.035364  0.099931  0.048464  0.030324 -0.068622  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604510</td>\n",
       "      <td>0.588426</td>\n",
       "      <td>-0.205228</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>1.973900</td>\n",
       "      <td>1.260330</td>\n",
       "      <td>0.717597</td>\n",
       "      <td>1.013724</td>\n",
       "      <td>-0.201380</td>\n",
       "      <td>0.077659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.626707</td>\n",
       "      <td>0.719043</td>\n",
       "      <td>0.182539</td>\n",
       "      <td>0.493354</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>-0.324439</td>\n",
       "      <td>0.127469</td>\n",
       "      <td>0.527457</td>\n",
       "      <td>0.404922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561814</td>\n",
       "      <td>0.511812</td>\n",
       "      <td>-0.280863</td>\n",
       "      <td>0.716274</td>\n",
       "      <td>1.867069</td>\n",
       "      <td>1.569808</td>\n",
       "      <td>0.585808</td>\n",
       "      <td>1.147880</td>\n",
       "      <td>0.075876</td>\n",
       "      <td>0.137893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080376</td>\n",
       "      <td>0.465956</td>\n",
       "      <td>0.626413</td>\n",
       "      <td>-0.045534</td>\n",
       "      <td>0.617220</td>\n",
       "      <td>0.433061</td>\n",
       "      <td>-0.304907</td>\n",
       "      <td>0.286128</td>\n",
       "      <td>0.394571</td>\n",
       "      <td>0.266304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546373</td>\n",
       "      <td>0.062498</td>\n",
       "      <td>-0.327004</td>\n",
       "      <td>0.813788</td>\n",
       "      <td>1.416170</td>\n",
       "      <td>1.549371</td>\n",
       "      <td>0.558580</td>\n",
       "      <td>1.150737</td>\n",
       "      <td>0.253067</td>\n",
       "      <td>0.110696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163509</td>\n",
       "      <td>0.193838</td>\n",
       "      <td>0.660893</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>0.672460</td>\n",
       "      <td>0.075143</td>\n",
       "      <td>-0.237908</td>\n",
       "      <td>0.360987</td>\n",
       "      <td>0.328562</td>\n",
       "      <td>-0.031578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512255</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.322989</td>\n",
       "      <td>0.861922</td>\n",
       "      <td>1.365365</td>\n",
       "      <td>1.539171</td>\n",
       "      <td>0.485873</td>\n",
       "      <td>1.161082</td>\n",
       "      <td>0.469912</td>\n",
       "      <td>0.074668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154426</td>\n",
       "      <td>0.279764</td>\n",
       "      <td>0.655488</td>\n",
       "      <td>0.167106</td>\n",
       "      <td>0.683768</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>-0.257095</td>\n",
       "      <td>0.466250</td>\n",
       "      <td>0.340417</td>\n",
       "      <td>0.070660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.483263</td>\n",
       "      <td>-0.091438</td>\n",
       "      <td>-0.338230</td>\n",
       "      <td>0.893001</td>\n",
       "      <td>1.063844</td>\n",
       "      <td>1.575519</td>\n",
       "      <td>0.512306</td>\n",
       "      <td>1.160689</td>\n",
       "      <td>0.390473</td>\n",
       "      <td>0.104820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136991</td>\n",
       "      <td>0.159172</td>\n",
       "      <td>0.606764</td>\n",
       "      <td>0.117792</td>\n",
       "      <td>0.785372</td>\n",
       "      <td>-0.158917</td>\n",
       "      <td>-0.198069</td>\n",
       "      <td>0.467135</td>\n",
       "      <td>0.286246</td>\n",
       "      <td>-0.143399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.604510  0.588426 -0.205228  0.671284  1.973900  1.260330  0.717597   \n",
       "1  0.561814  0.511812 -0.280863  0.716274  1.867069  1.569808  0.585808   \n",
       "2  0.546373  0.062498 -0.327004  0.813788  1.416170  1.549371  0.558580   \n",
       "3  0.512255  0.054458 -0.322989  0.861922  1.365365  1.539171  0.485873   \n",
       "4  0.483263 -0.091438 -0.338230  0.893001  1.063844  1.575519  0.512306   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  1.013724 -0.201380  0.077659  ...  0.011921  0.626707  0.719043  0.182539   \n",
       "1  1.147880  0.075876  0.137893  ... -0.080376  0.465956  0.626413 -0.045534   \n",
       "2  1.150737  0.253067  0.110696  ... -0.163509  0.193838  0.660893  0.044866   \n",
       "3  1.161082  0.469912  0.074668  ... -0.154426  0.279764  0.655488  0.167106   \n",
       "4  1.160689  0.390473  0.104820  ... -0.136991  0.159172  0.606764  0.117792   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0  0.493354  0.631235 -0.324439  0.127469  0.527457  0.404922  \n",
       "1  0.617220  0.433061 -0.304907  0.286128  0.394571  0.266304  \n",
       "2  0.672460  0.075143 -0.237908  0.360987  0.328562 -0.031578  \n",
       "3  0.683768  0.027333 -0.257095  0.466250  0.340417  0.070660  \n",
       "4  0.785372 -0.158917 -0.198069  0.467135  0.286246 -0.143399  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=19.582977294921875\n",
      "Epoch #1: validation loss=19.5350341796875\n",
      "\n",
      "Epoch #2: train loss=19.56104278564453\n",
      "Epoch #2: validation loss=19.354076385498047\n",
      "\n",
      "Epoch #3: train loss=19.525501251220703\n",
      "Epoch #3: validation loss=20.442901611328125\n",
      "\n",
      "Epoch #4: train loss=19.49390983581543\n",
      "Epoch #4: validation loss=19.357648849487305\n",
      "\n",
      "Epoch #5: train loss=19.48751449584961\n",
      "Epoch #5: validation loss=19.4041690826416\n",
      "\n",
      "Epoch #6: train loss=19.45798110961914\n",
      "Epoch #6: validation loss=19.630054473876953\n",
      "\n",
      "Epoch #7: train loss=19.44181251525879\n",
      "Epoch #7: validation loss=19.73177719116211\n",
      "\n",
      "Epoch #8: train loss=19.39997100830078\n",
      "Epoch #8: validation loss=20.054264068603516\n",
      "\n",
      "Epoch #9: train loss=19.373287200927734\n",
      "Epoch #9: validation loss=19.525205612182617\n",
      "\n",
      "Epoch #10: train loss=19.33846664428711\n",
      "Epoch #10: validation loss=19.444679260253906\n",
      "\n",
      "Epoch #11: train loss=19.32611656188965\n",
      "Epoch #11: validation loss=19.415756225585938\n",
      "\n",
      "Epoch #12: train loss=19.261075973510742\n",
      "Epoch #12: validation loss=19.319114685058594\n",
      "\n",
      "Epoch #13: train loss=19.237552642822266\n",
      "Epoch #13: validation loss=19.387435913085938\n",
      "\n",
      "Epoch #14: train loss=19.138050079345703\n",
      "Epoch #14: validation loss=19.390342712402344\n",
      "\n",
      "Epoch #15: train loss=19.18966293334961\n",
      "Epoch #15: validation loss=19.18710708618164\n",
      "\n",
      "Epoch #16: train loss=19.15951156616211\n",
      "Epoch #16: validation loss=19.936317443847656\n",
      "\n",
      "Epoch #17: train loss=19.02560806274414\n",
      "Epoch #17: validation loss=19.182754516601562\n",
      "\n",
      "Epoch #18: train loss=18.96500587463379\n",
      "Epoch #18: validation loss=19.50770378112793\n",
      "\n",
      "Epoch #19: train loss=18.905635833740234\n",
      "Epoch #19: validation loss=18.94622802734375\n",
      "\n",
      "Epoch #20: train loss=18.858985900878906\n",
      "Epoch #20: validation loss=18.93308448791504\n",
      "\n",
      "Epoch #21: train loss=18.76458740234375\n",
      "Epoch #21: validation loss=19.499225616455078\n",
      "\n",
      "Epoch #22: train loss=18.73495101928711\n",
      "Epoch #22: validation loss=18.820728302001953\n",
      "\n",
      "Epoch #23: train loss=18.587705612182617\n",
      "Epoch #23: validation loss=18.687339782714844\n",
      "\n",
      "Epoch #24: train loss=18.690208435058594\n",
      "Epoch #24: validation loss=18.6202335357666\n",
      "\n",
      "Epoch #25: train loss=18.533506393432617\n",
      "Epoch #25: validation loss=18.825986862182617\n",
      "\n",
      "Epoch #26: train loss=18.501941680908203\n",
      "Epoch #26: validation loss=19.087186813354492\n",
      "\n",
      "Epoch #27: train loss=18.285791397094727\n",
      "Epoch #27: validation loss=18.500598907470703\n",
      "\n",
      "Epoch #28: train loss=18.30495834350586\n",
      "Epoch #28: validation loss=18.468364715576172\n",
      "\n",
      "Epoch #29: train loss=18.255237579345703\n",
      "Epoch #29: validation loss=18.59807586669922\n",
      "\n",
      "Epoch #30: train loss=18.315170288085938\n",
      "Epoch #30: validation loss=18.634449005126953\n",
      "\n",
      "Epoch #31: train loss=18.28331184387207\n",
      "Epoch #31: validation loss=18.469329833984375\n",
      "\n",
      "Epoch #32: train loss=18.375627517700195\n",
      "Epoch #32: validation loss=18.583215713500977\n",
      "\n",
      "Epoch #33: train loss=18.13300323486328\n",
      "Epoch #33: validation loss=18.530006408691406\n",
      "\n",
      "Epoch #34: train loss=18.4135799407959\n",
      "Epoch #34: validation loss=18.438825607299805\n",
      "\n",
      "Epoch #35: train loss=18.188302993774414\n",
      "Epoch #35: validation loss=18.794139862060547\n",
      "\n",
      "Epoch #36: train loss=18.060428619384766\n",
      "Epoch #36: validation loss=18.472061157226562\n",
      "\n",
      "Epoch #37: train loss=18.18587875366211\n",
      "Epoch #37: validation loss=18.215152740478516\n",
      "\n",
      "Epoch #38: train loss=18.161739349365234\n",
      "Epoch #38: validation loss=18.28907585144043\n",
      "\n",
      "Epoch #39: train loss=18.28355598449707\n",
      "Epoch #39: validation loss=18.224807739257812\n",
      "\n",
      "Epoch #40: train loss=18.05512809753418\n",
      "Epoch #40: validation loss=18.186965942382812\n",
      "\n",
      "Epoch #41: train loss=18.131038665771484\n",
      "Epoch #41: validation loss=18.373722076416016\n",
      "\n",
      "Epoch #42: train loss=18.24888038635254\n",
      "Epoch #42: validation loss=18.47772979736328\n",
      "\n",
      "Epoch #43: train loss=17.990848541259766\n",
      "Epoch #43: validation loss=18.129209518432617\n",
      "\n",
      "Epoch #44: train loss=18.037321090698242\n",
      "Epoch #44: validation loss=18.336971282958984\n",
      "\n",
      "Epoch #45: train loss=18.067312240600586\n",
      "Epoch #45: validation loss=18.225231170654297\n",
      "\n",
      "Epoch #46: train loss=18.04193878173828\n",
      "Epoch #46: validation loss=18.256877899169922\n",
      "\n",
      "Epoch #47: train loss=18.034725189208984\n",
      "Epoch #47: validation loss=18.31737518310547\n",
      "\n",
      "Epoch #48: train loss=17.969139099121094\n",
      "Epoch #48: validation loss=18.58904266357422\n",
      "\n",
      "Epoch #49: train loss=17.97243309020996\n",
      "Epoch #49: validation loss=18.104843139648438\n",
      "\n",
      "Epoch #50: train loss=18.184816360473633\n",
      "Epoch #50: validation loss=18.5333309173584\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. model = ts_tcc\n",
    "config = config2\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.744626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829155</td>\n",
       "      <td>1.488290</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.981022</td>\n",
       "      <td>1.103711</td>\n",
       "      <td>1.479490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.870526</td>\n",
       "      <td>1.530592</td>\n",
       "      <td>1.190534</td>\n",
       "      <td>0.524825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192903</td>\n",
       "      <td>0.654648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.533573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.726559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832423</td>\n",
       "      <td>1.431869</td>\n",
       "      <td>1.024122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.989928</td>\n",
       "      <td>1.070720</td>\n",
       "      <td>1.485404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854669</td>\n",
       "      <td>1.538515</td>\n",
       "      <td>1.211092</td>\n",
       "      <td>0.509399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258388</td>\n",
       "      <td>0.676524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.532583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819706</td>\n",
       "      <td>1.413890</td>\n",
       "      <td>1.023439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.995048</td>\n",
       "      <td>1.068986</td>\n",
       "      <td>1.473787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.847066</td>\n",
       "      <td>1.532187</td>\n",
       "      <td>1.199001</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270424</td>\n",
       "      <td>0.676852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.532341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821733</td>\n",
       "      <td>1.390979</td>\n",
       "      <td>1.034416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003811</td>\n",
       "      <td>1.071950</td>\n",
       "      <td>1.477579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.859940</td>\n",
       "      <td>1.531603</td>\n",
       "      <td>1.199053</td>\n",
       "      <td>0.515407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286682</td>\n",
       "      <td>0.677910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828449</td>\n",
       "      <td>1.396067</td>\n",
       "      <td>1.035022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001043</td>\n",
       "      <td>1.058323</td>\n",
       "      <td>1.483781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865437</td>\n",
       "      <td>1.531960</td>\n",
       "      <td>1.196236</td>\n",
       "      <td>0.518705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289590</td>\n",
       "      <td>0.683015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.521953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1   V2   V3        V4        V5        V6   V7        V8        V9  \\\n",
       "0  0.744626  0.0  0.0  0.829155  1.488290  0.973557  0.0  1.981022  1.103711   \n",
       "1  0.726559  0.0  0.0  0.832423  1.431869  1.024122  0.0  1.989928  1.070720   \n",
       "2  0.721764  0.0  0.0  0.819706  1.413890  1.023439  0.0  1.995048  1.068986   \n",
       "3  0.705584  0.0  0.0  0.821733  1.390979  1.034416  0.0  2.003811  1.071950   \n",
       "4  0.713996  0.0  0.0  0.828449  1.396067  1.035022  0.0  2.001043  1.058323   \n",
       "\n",
       "        V10  ...  V55       V56       V57       V58       V59  V60       V61  \\\n",
       "0  1.479490  ...  0.0  1.870526  1.530592  1.190534  0.524825  0.0  0.192903   \n",
       "1  1.485404  ...  0.0  1.854669  1.538515  1.211092  0.509399  0.0  0.258388   \n",
       "2  1.473787  ...  0.0  1.847066  1.532187  1.199001  0.509043  0.0  0.270424   \n",
       "3  1.477579  ...  0.0  1.859940  1.531603  1.199053  0.515407  0.0  0.286682   \n",
       "4  1.483781  ...  0.0  1.865437  1.531960  1.196236  0.518705  0.0  0.289590   \n",
       "\n",
       "        V62  V63       V64  \n",
       "0  0.654648  0.0  1.533573  \n",
       "1  0.676524  0.0  1.532583  \n",
       "2  0.676852  0.0  1.532341  \n",
       "3  0.677910  0.0  1.527292  \n",
       "4  0.683015  0.0  1.521953  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.019318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835575</td>\n",
       "      <td>1.651087</td>\n",
       "      <td>0.785979</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>2.017650</td>\n",
       "      <td>1.134924</td>\n",
       "      <td>1.429579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.809016</td>\n",
       "      <td>1.544034</td>\n",
       "      <td>1.173692</td>\n",
       "      <td>0.443830</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>0.280080</td>\n",
       "      <td>0.788252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.467388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828378</td>\n",
       "      <td>1.448049</td>\n",
       "      <td>1.071115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.984238</td>\n",
       "      <td>1.010257</td>\n",
       "      <td>1.432151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.840703</td>\n",
       "      <td>1.527592</td>\n",
       "      <td>1.154068</td>\n",
       "      <td>0.457090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305323</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823715</td>\n",
       "      <td>1.361779</td>\n",
       "      <td>1.069044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.005557</td>\n",
       "      <td>1.029939</td>\n",
       "      <td>1.418222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.824186</td>\n",
       "      <td>1.515320</td>\n",
       "      <td>1.159892</td>\n",
       "      <td>0.465052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364472</td>\n",
       "      <td>0.692511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.554687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817371</td>\n",
       "      <td>1.392371</td>\n",
       "      <td>1.060552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.990492</td>\n",
       "      <td>1.039663</td>\n",
       "      <td>1.420777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.827514</td>\n",
       "      <td>1.516359</td>\n",
       "      <td>1.148880</td>\n",
       "      <td>0.457974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328887</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.554501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831737</td>\n",
       "      <td>1.356451</td>\n",
       "      <td>1.077132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.999531</td>\n",
       "      <td>1.031571</td>\n",
       "      <td>1.438225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.850438</td>\n",
       "      <td>1.516683</td>\n",
       "      <td>1.140328</td>\n",
       "      <td>0.449178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349859</td>\n",
       "      <td>0.700667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1   V2   V3        V4        V5        V6        V7        V8  \\\n",
       "0  1.019318  0.0  0.0  0.835575  1.651087  0.785979  0.017311  2.017650   \n",
       "1  0.729495  0.0  0.0  0.828378  1.448049  1.071115  0.000000  1.984238   \n",
       "2  0.736129  0.0  0.0  0.823715  1.361779  1.069044  0.000000  2.005557   \n",
       "3  0.749357  0.0  0.0  0.817371  1.392371  1.060552  0.000000  1.990492   \n",
       "4  0.735662  0.0  0.0  0.831737  1.356451  1.077132  0.000000  1.999531   \n",
       "\n",
       "         V9       V10  ...  V55       V56       V57       V58       V59  \\\n",
       "0  1.134924  1.429579  ...  0.0  1.809016  1.544034  1.173692  0.443830   \n",
       "1  1.010257  1.432151  ...  0.0  1.840703  1.527592  1.154068  0.457090   \n",
       "2  1.029939  1.418222  ...  0.0  1.824186  1.515320  1.159892  0.465052   \n",
       "3  1.039663  1.420777  ...  0.0  1.827514  1.516359  1.148880  0.457974   \n",
       "4  1.031571  1.438225  ...  0.0  1.850438  1.516683  1.140328  0.449178   \n",
       "\n",
       "        V60       V61       V62  V63       V64  \n",
       "0  0.030953  0.280080  0.788252  0.0  1.467388  \n",
       "1  0.000000  0.305323  0.679145  0.0  1.599990  \n",
       "2  0.000000  0.364472  0.692511  0.0  1.554687  \n",
       "3  0.000000  0.328887  0.695106  0.0  1.554501  \n",
       "4  0.000000  0.349859  0.700667  0.0  1.555602  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: train loss=0.325350284576416\n",
      "Epoch #1: validation loss=0.1690431386232376\n",
      "\n",
      "Epoch #2: train loss=0.3037114143371582\n",
      "Epoch #2: validation loss=0.15433645248413086\n",
      "\n",
      "Epoch #3: train loss=0.28291401267051697\n",
      "Epoch #3: validation loss=0.1394573450088501\n",
      "\n",
      "Epoch #4: train loss=0.26264896988868713\n",
      "Epoch #4: validation loss=0.1264355331659317\n",
      "\n",
      "Epoch #5: train loss=0.2424534112215042\n",
      "Epoch #5: validation loss=0.11284668743610382\n",
      "\n",
      "Epoch #6: train loss=0.22465625405311584\n",
      "Epoch #6: validation loss=0.10531354695558548\n",
      "\n",
      "Epoch #7: train loss=0.2125057578086853\n",
      "Epoch #7: validation loss=0.10442522168159485\n",
      "\n",
      "Epoch #8: train loss=0.2028370499610901\n",
      "Epoch #8: validation loss=0.1033286601305008\n",
      "\n",
      "Epoch #9: train loss=0.193651482462883\n",
      "Epoch #9: validation loss=0.10279160737991333\n",
      "\n",
      "Epoch #10: train loss=0.18893495202064514\n",
      "Epoch #10: validation loss=0.10294356942176819\n",
      "\n",
      "Epoch #11: train loss=0.18549083173274994\n",
      "Epoch #11: validation loss=0.10147477686405182\n",
      "\n",
      "Epoch #12: train loss=0.1823497861623764\n",
      "Epoch #12: validation loss=0.10071170330047607\n",
      "\n",
      "Epoch #13: train loss=0.1782684624195099\n",
      "Epoch #13: validation loss=0.09869170188903809\n",
      "\n",
      "Epoch #14: train loss=0.1731753796339035\n",
      "Epoch #14: validation loss=0.0945812314748764\n",
      "\n",
      "Epoch #15: train loss=0.16616936028003693\n",
      "Epoch #15: validation loss=0.08954185992479324\n",
      "\n",
      "Epoch #16: train loss=0.157677561044693\n",
      "Epoch #16: validation loss=0.08364551514387131\n",
      "\n",
      "Epoch #17: train loss=0.14981432259082794\n",
      "Epoch #17: validation loss=0.07860349118709564\n",
      "\n",
      "Epoch #18: train loss=0.14211955666542053\n",
      "Epoch #18: validation loss=0.07401066273450851\n",
      "\n",
      "Epoch #19: train loss=0.1374780535697937\n",
      "Epoch #19: validation loss=0.07036326080560684\n",
      "\n",
      "Epoch #20: train loss=0.1336716264486313\n",
      "Epoch #20: validation loss=0.06917238235473633\n",
      "\n",
      "Epoch #21: train loss=0.13133986294269562\n",
      "Epoch #21: validation loss=0.06758534163236618\n",
      "\n",
      "Epoch #22: train loss=0.12914186716079712\n",
      "Epoch #22: validation loss=0.06615728884935379\n",
      "\n",
      "Epoch #23: train loss=0.12735506892204285\n",
      "Epoch #23: validation loss=0.06521128863096237\n",
      "\n",
      "Epoch #24: train loss=0.1259196549654007\n",
      "Epoch #24: validation loss=0.0644790306687355\n",
      "\n",
      "Epoch #25: train loss=0.12374402582645416\n",
      "Epoch #25: validation loss=0.06316851079463959\n",
      "\n",
      "Epoch #26: train loss=0.1215706542134285\n",
      "Epoch #26: validation loss=0.06217057630419731\n",
      "\n",
      "Epoch #27: train loss=0.1194191426038742\n",
      "Epoch #27: validation loss=0.06021898612380028\n",
      "\n",
      "Epoch #28: train loss=0.11679453402757645\n",
      "Epoch #28: validation loss=0.058203134685754776\n",
      "\n",
      "Epoch #29: train loss=0.11370015144348145\n",
      "Epoch #29: validation loss=0.056456562131643295\n",
      "\n",
      "Epoch #30: train loss=0.11161739379167557\n",
      "Epoch #30: validation loss=0.0549396276473999\n",
      "\n",
      "Epoch #31: train loss=0.1096697747707367\n",
      "Epoch #31: validation loss=0.05464281886816025\n",
      "\n",
      "Epoch #32: train loss=0.1078440472483635\n",
      "Epoch #32: validation loss=0.052712637931108475\n",
      "\n",
      "Epoch #33: train loss=0.10650188475847244\n",
      "Epoch #33: validation loss=0.05232853442430496\n",
      "\n",
      "Epoch #34: train loss=0.10502879321575165\n",
      "Epoch #34: validation loss=0.05213915556669235\n",
      "\n",
      "Epoch #35: train loss=0.10361803323030472\n",
      "Epoch #35: validation loss=0.05129900947213173\n",
      "\n",
      "Epoch #36: train loss=0.10223142802715302\n",
      "Epoch #36: validation loss=0.05058174207806587\n",
      "\n",
      "Epoch #37: train loss=0.10110627859830856\n",
      "Epoch #37: validation loss=0.050499334931373596\n",
      "\n",
      "Epoch #38: train loss=0.09999562054872513\n",
      "Epoch #38: validation loss=0.04986078664660454\n",
      "\n",
      "Epoch #39: train loss=0.09904549270868301\n",
      "Epoch #39: validation loss=0.04960426688194275\n",
      "\n",
      "Epoch #40: train loss=0.09777987748384476\n",
      "Epoch #40: validation loss=0.04864426702260971\n",
      "\n",
      "Epoch #41: train loss=0.09693509340286255\n",
      "Epoch #41: validation loss=0.04836467280983925\n",
      "\n",
      "Epoch #42: train loss=0.0960497036576271\n",
      "Epoch #42: validation loss=0.04760577157139778\n",
      "\n",
      "Epoch #43: train loss=0.09489414840936661\n",
      "Epoch #43: validation loss=0.04712378606200218\n",
      "\n",
      "Epoch #44: train loss=0.09411861002445221\n",
      "Epoch #44: validation loss=0.04656554386019707\n",
      "\n",
      "Epoch #45: train loss=0.09293216466903687\n",
      "Epoch #45: validation loss=0.04563305154442787\n",
      "\n",
      "Epoch #46: train loss=0.09184058010578156\n",
      "Epoch #46: validation loss=0.044887371361255646\n",
      "\n",
      "Epoch #47: train loss=0.09091275185346603\n",
      "Epoch #47: validation loss=0.04409007355570793\n",
      "\n",
      "Epoch #48: train loss=0.08986902981996536\n",
      "Epoch #48: validation loss=0.04315010458230972\n",
      "\n",
      "Epoch #49: train loss=0.08908688277006149\n",
      "Epoch #49: validation loss=0.043008044362068176\n",
      "\n",
      "Epoch #50: train loss=0.0880097821354866\n",
      "Epoch #50: validation loss=0.042430102825164795\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. model = rae_mepc\n",
    "config = config3\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.688607</td>\n",
       "      <td>0.061593</td>\n",
       "      <td>-0.383556</td>\n",
       "      <td>0.948981</td>\n",
       "      <td>-0.580462</td>\n",
       "      <td>0.291508</td>\n",
       "      <td>-0.491042</td>\n",
       "      <td>0.131423</td>\n",
       "      <td>-0.563544</td>\n",
       "      <td>-0.440816</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158566</td>\n",
       "      <td>0.718064</td>\n",
       "      <td>-0.633171</td>\n",
       "      <td>-1.037993</td>\n",
       "      <td>-0.654820</td>\n",
       "      <td>-1.400875</td>\n",
       "      <td>1.300124</td>\n",
       "      <td>0.142990</td>\n",
       "      <td>1.256600</td>\n",
       "      <td>0.338931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.703893</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>-0.387369</td>\n",
       "      <td>0.938212</td>\n",
       "      <td>-0.573998</td>\n",
       "      <td>0.286079</td>\n",
       "      <td>-0.479039</td>\n",
       "      <td>0.131423</td>\n",
       "      <td>-0.562809</td>\n",
       "      <td>-0.424822</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158379</td>\n",
       "      <td>0.716326</td>\n",
       "      <td>-0.631527</td>\n",
       "      <td>-1.052797</td>\n",
       "      <td>-0.672248</td>\n",
       "      <td>-1.400875</td>\n",
       "      <td>1.300124</td>\n",
       "      <td>0.121656</td>\n",
       "      <td>1.239977</td>\n",
       "      <td>0.322619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.712129</td>\n",
       "      <td>0.083974</td>\n",
       "      <td>-0.391321</td>\n",
       "      <td>0.930104</td>\n",
       "      <td>-0.573998</td>\n",
       "      <td>0.286425</td>\n",
       "      <td>-0.471686</td>\n",
       "      <td>0.127747</td>\n",
       "      <td>-0.556572</td>\n",
       "      <td>-0.417296</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158379</td>\n",
       "      <td>0.719549</td>\n",
       "      <td>-0.631527</td>\n",
       "      <td>-1.064433</td>\n",
       "      <td>-0.679306</td>\n",
       "      <td>-1.402853</td>\n",
       "      <td>1.308658</td>\n",
       "      <td>0.114472</td>\n",
       "      <td>1.234172</td>\n",
       "      <td>0.313113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.722868</td>\n",
       "      <td>0.083974</td>\n",
       "      <td>-0.386363</td>\n",
       "      <td>0.943948</td>\n",
       "      <td>-0.589505</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>-0.461986</td>\n",
       "      <td>0.132758</td>\n",
       "      <td>-0.555541</td>\n",
       "      <td>-0.417296</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.161435</td>\n",
       "      <td>0.719549</td>\n",
       "      <td>-0.635632</td>\n",
       "      <td>-1.060184</td>\n",
       "      <td>-0.664306</td>\n",
       "      <td>-1.408921</td>\n",
       "      <td>1.317508</td>\n",
       "      <td>0.101543</td>\n",
       "      <td>1.224174</td>\n",
       "      <td>0.308647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.704933</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>-0.380772</td>\n",
       "      <td>0.956162</td>\n",
       "      <td>-0.586930</td>\n",
       "      <td>0.299106</td>\n",
       "      <td>-0.461986</td>\n",
       "      <td>0.138202</td>\n",
       "      <td>-0.555541</td>\n",
       "      <td>-0.426082</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.168403</td>\n",
       "      <td>0.718252</td>\n",
       "      <td>-0.636969</td>\n",
       "      <td>-1.049286</td>\n",
       "      <td>-0.656282</td>\n",
       "      <td>-1.403172</td>\n",
       "      <td>1.321968</td>\n",
       "      <td>0.119792</td>\n",
       "      <td>1.240214</td>\n",
       "      <td>0.322928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.688607  0.061593 -0.383556  0.948981 -0.580462  0.291508 -0.491042   \n",
       "1 -0.703893  0.073500 -0.387369  0.938212 -0.573998  0.286079 -0.479039   \n",
       "2 -0.712129  0.083974 -0.391321  0.930104 -0.573998  0.286425 -0.471686   \n",
       "3 -0.722868  0.083974 -0.386363  0.943948 -0.589505  0.293000 -0.461986   \n",
       "4 -0.704933  0.074808 -0.380772  0.956162 -0.586930  0.299106 -0.461986   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  0.131423 -0.563544 -0.440816  ... -1.158566  0.718064 -0.633171 -1.037993   \n",
       "1  0.131423 -0.562809 -0.424822  ... -1.158379  0.716326 -0.631527 -1.052797   \n",
       "2  0.127747 -0.556572 -0.417296  ... -1.158379  0.719549 -0.631527 -1.064433   \n",
       "3  0.132758 -0.555541 -0.417296  ... -1.161435  0.719549 -0.635632 -1.060184   \n",
       "4  0.138202 -0.555541 -0.426082  ... -1.168403  0.718252 -0.636969 -1.049286   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.654820 -1.400875  1.300124  0.142990  1.256600  0.338931  \n",
       "1 -0.672248 -1.400875  1.300124  0.121656  1.239977  0.322619  \n",
       "2 -0.679306 -1.402853  1.308658  0.114472  1.234172  0.313113  \n",
       "3 -0.664306 -1.408921  1.317508  0.101543  1.224174  0.308647  \n",
       "4 -0.656282 -1.403172  1.321968  0.119792  1.240214  0.322928  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.557617</td>\n",
       "      <td>0.160285</td>\n",
       "      <td>-0.425887</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>-0.602728</td>\n",
       "      <td>0.237714</td>\n",
       "      <td>-0.521347</td>\n",
       "      <td>0.143738</td>\n",
       "      <td>-0.537697</td>\n",
       "      <td>-0.372173</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.094319</td>\n",
       "      <td>0.778685</td>\n",
       "      <td>-0.662305</td>\n",
       "      <td>-1.071405</td>\n",
       "      <td>-0.717448</td>\n",
       "      <td>-1.414683</td>\n",
       "      <td>1.224193</td>\n",
       "      <td>0.227640</td>\n",
       "      <td>1.294488</td>\n",
       "      <td>0.406175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.669349</td>\n",
       "      <td>0.160285</td>\n",
       "      <td>-0.419329</td>\n",
       "      <td>0.874844</td>\n",
       "      <td>-0.614556</td>\n",
       "      <td>0.232385</td>\n",
       "      <td>-0.493306</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>-0.511537</td>\n",
       "      <td>-0.372173</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.094319</td>\n",
       "      <td>0.793442</td>\n",
       "      <td>-0.654049</td>\n",
       "      <td>-1.082455</td>\n",
       "      <td>-0.717448</td>\n",
       "      <td>-1.427174</td>\n",
       "      <td>1.265099</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>1.204864</td>\n",
       "      <td>0.337063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.698920</td>\n",
       "      <td>0.143665</td>\n",
       "      <td>-0.419329</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>-0.648730</td>\n",
       "      <td>0.232652</td>\n",
       "      <td>-0.477078</td>\n",
       "      <td>0.095774</td>\n",
       "      <td>-0.511537</td>\n",
       "      <td>-0.393631</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.102755</td>\n",
       "      <td>0.793442</td>\n",
       "      <td>-0.653244</td>\n",
       "      <td>-1.094098</td>\n",
       "      <td>-0.710921</td>\n",
       "      <td>-1.452243</td>\n",
       "      <td>1.265099</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>1.189459</td>\n",
       "      <td>0.300597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.698920</td>\n",
       "      <td>0.137622</td>\n",
       "      <td>-0.405124</td>\n",
       "      <td>0.938751</td>\n",
       "      <td>-0.648730</td>\n",
       "      <td>0.243397</td>\n",
       "      <td>-0.446895</td>\n",
       "      <td>0.101446</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-0.394289</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095365</td>\n",
       "      <td>0.791849</td>\n",
       "      <td>-0.653244</td>\n",
       "      <td>-1.071329</td>\n",
       "      <td>-0.667992</td>\n",
       "      <td>-1.452243</td>\n",
       "      <td>1.302684</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>1.189459</td>\n",
       "      <td>0.306359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.755224</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>-0.398618</td>\n",
       "      <td>0.967627</td>\n",
       "      <td>-0.650972</td>\n",
       "      <td>0.255839</td>\n",
       "      <td>-0.445786</td>\n",
       "      <td>0.117957</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-0.394289</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095365</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>-0.657758</td>\n",
       "      <td>-1.049908</td>\n",
       "      <td>-0.653448</td>\n",
       "      <td>-1.457068</td>\n",
       "      <td>1.308867</td>\n",
       "      <td>0.112376</td>\n",
       "      <td>1.161752</td>\n",
       "      <td>0.337753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.557617  0.160285 -0.425887  0.864598 -0.602728  0.237714 -0.521347   \n",
       "1 -0.669349  0.160285 -0.419329  0.874844 -0.614556  0.232385 -0.493306   \n",
       "2 -0.698920  0.143665 -0.419329  0.881700 -0.648730  0.232652 -0.477078   \n",
       "3 -0.698920  0.137622 -0.405124  0.938751 -0.648730  0.243397 -0.446895   \n",
       "4 -0.755224  0.133954 -0.398618  0.967627 -0.650972  0.255839 -0.445786   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0  0.143738 -0.537697 -0.372173  ... -1.094319  0.778685 -0.662305 -1.071405   \n",
       "1  0.100120 -0.511537 -0.372173  ... -1.094319  0.793442 -0.654049 -1.082455   \n",
       "2  0.095774 -0.511537 -0.393631  ... -1.102755  0.793442 -0.653244 -1.094098   \n",
       "3  0.101446 -0.499092 -0.394289  ... -1.095365  0.791849 -0.653244 -1.071329   \n",
       "4  0.117957 -0.499092 -0.394289  ... -1.095365  0.783666 -0.657758 -1.049908   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.717448 -1.414683  1.224193  0.227640  1.294488  0.406175  \n",
       "1 -0.717448 -1.427174  1.265099  0.152401  1.204864  0.337063  \n",
       "2 -0.710921 -1.452243  1.265099  0.125598  1.189459  0.300597  \n",
       "3 -0.667992 -1.452243  1.302684  0.125598  1.189459  0.306359  \n",
       "4 -0.653448 -1.457068  1.308867  0.112376  1.161752  0.337753  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch #1: loss=1.6170785913572592\n",
      "Epoch #1: validation loss=0.10995912365615368\n",
      "\n",
      "Epoch #2: loss=0.10599795334479388\n",
      "Epoch #2: validation loss=0.09988718666136265\n",
      "\n",
      "Epoch #3: loss=0.09985399553004433\n",
      "Epoch #3: validation loss=0.09597376547753811\n",
      "\n",
      "Epoch #4: loss=0.09701299755012288\n",
      "Epoch #4: validation loss=0.09307925403118134\n",
      "\n",
      "Epoch #5: loss=0.09459449394660838\n",
      "Epoch #5: validation loss=0.09128953516483307\n",
      "\n",
      "Epoch #6: loss=0.09341227570000817\n",
      "Epoch #6: validation loss=0.09153063222765923\n",
      "\n",
      "Epoch #7: loss=0.09308350787443273\n",
      "Epoch #7: validation loss=0.09027368389070034\n",
      "\n",
      "Epoch #8: loss=0.09114879808005165\n",
      "Epoch #8: validation loss=0.08633670583367348\n",
      "\n",
      "Epoch #9: loss=0.08312011115691241\n",
      "Epoch #9: validation loss=0.0729949064552784\n",
      "\n",
      "Epoch #10: loss=0.07183623401557698\n",
      "Epoch #10: validation loss=0.0637363288551569\n",
      "\n",
      "Epoch #11: loss=0.05888085001531769\n",
      "Epoch #11: validation loss=0.04443054273724556\n",
      "\n",
      "Epoch #12: loss=0.04168248264228597\n",
      "Epoch #12: validation loss=0.030969254206866026\n",
      "\n",
      "Epoch #13: loss=0.03463355714783949\n",
      "Epoch #13: validation loss=0.02827613754197955\n",
      "\n",
      "Epoch #14: loss=0.031079661648939636\n",
      "Epoch #14: validation loss=0.02501640748232603\n",
      "\n",
      "Epoch #15: loss=0.028177401598762062\n",
      "Epoch #15: validation loss=0.022779235616326332\n",
      "\n",
      "Epoch #16: loss=0.026274590150398368\n",
      "Epoch #16: validation loss=0.021654788870364428\n",
      "\n",
      "Epoch #17: loss=0.02559213077320772\n",
      "Epoch #17: validation loss=0.02123647090047598\n",
      "\n",
      "Epoch #18: loss=0.025426174459211966\n",
      "Epoch #18: validation loss=0.021207372192293406\n",
      "\n",
      "Epoch #19: loss=0.0253059873905252\n",
      "Epoch #19: validation loss=0.021267144940793514\n",
      "\n",
      "Epoch #20: loss=0.02494337037205696\n",
      "Epoch #20: validation loss=0.02049660822376609\n",
      "\n",
      "Epoch #21: loss=0.023642924449899617\n",
      "Epoch #21: validation loss=0.01868634531274438\n",
      "\n",
      "Epoch #22: loss=0.021196662503130296\n",
      "Epoch #22: validation loss=0.015614847419783473\n",
      "\n",
      "Epoch #23: loss=0.018409471520606208\n",
      "Epoch #23: validation loss=0.013733247062191367\n",
      "\n",
      "Epoch #24: loss=0.016401843880029285\n",
      "Epoch #24: validation loss=0.012264633784070611\n",
      "\n",
      "Epoch #25: loss=0.014506570940070292\n",
      "Epoch #25: validation loss=0.010495531838387251\n",
      "\n",
      "Epoch #26: loss=0.012661026133333935\n",
      "Epoch #26: validation loss=0.0086620703805238\n",
      "\n",
      "Epoch #27: loss=0.01097928749068695\n",
      "Epoch #27: validation loss=0.007382086245343089\n",
      "\n",
      "Epoch #28: loss=0.010016657521619517\n",
      "Epoch #28: validation loss=0.0067213199799880385\n",
      "\n",
      "Epoch #29: loss=0.009633012280306396\n",
      "Epoch #29: validation loss=0.0064433414954692125\n",
      "\n",
      "Epoch #30: loss=0.009576971642673016\n",
      "Epoch #30: validation loss=0.006507989834062755\n",
      "\n",
      "Epoch #31: loss=0.00947526130167877\n",
      "Epoch #31: validation loss=0.006373401032760739\n",
      "\n",
      "Epoch #32: loss=0.009141962043941021\n",
      "Epoch #32: validation loss=0.00584621075540781\n",
      "\n",
      "Epoch #33: loss=0.008481760454528472\n",
      "Epoch #33: validation loss=0.0052931399550288916\n",
      "\n",
      "Epoch #34: loss=0.008226070525672506\n",
      "Epoch #34: validation loss=0.005421753274276853\n",
      "\n",
      "Epoch #35: loss=0.008919191272819744\n",
      "Epoch #35: validation loss=0.00568329484667629\n",
      "\n",
      "Epoch #36: loss=0.006893287248471204\n",
      "Epoch #36: validation loss=0.004120696918107569\n",
      "\n",
      "Epoch #37: loss=0.006101554122698658\n",
      "Epoch #37: validation loss=0.0035053465981036425\n",
      "\n",
      "Epoch #38: loss=0.005716709146166549\n",
      "Epoch #38: validation loss=0.0032630449859425426\n",
      "\n",
      "Epoch #39: loss=0.00550780858954086\n",
      "Epoch #39: validation loss=0.003128782147541642\n",
      "\n",
      "Epoch #40: loss=0.005392709637389463\n",
      "Epoch #40: validation loss=0.003106436284724623\n",
      "\n",
      "Epoch #41: loss=0.005343766472138026\n",
      "Epoch #41: validation loss=0.003075030108448118\n",
      "\n",
      "Epoch #42: loss=0.005320182453621836\n",
      "Epoch #42: validation loss=0.003057463967707008\n",
      "\n",
      "Epoch #43: loss=0.005320422762237927\n",
      "Epoch #43: validation loss=0.003044067823793739\n",
      "\n",
      "Epoch #44: loss=0.005231351810781395\n",
      "Epoch #44: validation loss=0.0029666944756172597\n",
      "\n",
      "Epoch #45: loss=0.005079908762127161\n",
      "Epoch #45: validation loss=0.002802480012178421\n",
      "\n",
      "Epoch #46: loss=0.005033320062519873\n",
      "Epoch #46: validation loss=0.003872315399348736\n",
      "\n",
      "Epoch #47: loss=0.006726362550740733\n",
      "Epoch #47: validation loss=0.003996323153842241\n",
      "\n",
      "Epoch #48: loss=0.004806424628066666\n",
      "Epoch #48: validation loss=0.0027382137486711144\n",
      "\n",
      "Epoch #49: loss=0.004272740772541831\n",
      "Epoch #49: validation loss=0.0022502641077153385\n",
      "\n",
      "Epoch #50: loss=0.004014757516629556\n",
      "Epoch #50: validation loss=0.002109747496433556\n",
      "\n",
      "Start encoding data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. model = stoc\n",
    "config = config4\n",
    "data_repr = mdr.Encode(config, train_data, test_data)\n",
    "model = data_repr.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_repr.train_model(model)  # 모델 학습\n",
    "    data_repr.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "train_repr, test_repr = data_repr.encode_data(model, best_model_path=config[\"best_model_path\"])  # representation 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64) (2947, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_repr.shape, test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.891249</td>\n",
       "      <td>-0.621638</td>\n",
       "      <td>0.417513</td>\n",
       "      <td>-0.284545</td>\n",
       "      <td>-0.251119</td>\n",
       "      <td>-0.463985</td>\n",
       "      <td>0.285838</td>\n",
       "      <td>-0.246278</td>\n",
       "      <td>-0.199712</td>\n",
       "      <td>-0.933221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>0.819481</td>\n",
       "      <td>-0.111247</td>\n",
       "      <td>0.792588</td>\n",
       "      <td>-0.989658</td>\n",
       "      <td>0.739370</td>\n",
       "      <td>0.144455</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.270035</td>\n",
       "      <td>-0.108632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.895377</td>\n",
       "      <td>-0.621640</td>\n",
       "      <td>0.430735</td>\n",
       "      <td>-0.274166</td>\n",
       "      <td>-0.251016</td>\n",
       "      <td>-0.459078</td>\n",
       "      <td>0.283579</td>\n",
       "      <td>-0.248442</td>\n",
       "      <td>-0.206698</td>\n",
       "      <td>-0.933221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.827522</td>\n",
       "      <td>-0.116565</td>\n",
       "      <td>0.808396</td>\n",
       "      <td>-0.994202</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.121209</td>\n",
       "      <td>0.340605</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>-0.114984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.903910</td>\n",
       "      <td>-0.621640</td>\n",
       "      <td>0.446909</td>\n",
       "      <td>-0.274166</td>\n",
       "      <td>-0.249243</td>\n",
       "      <td>-0.459078</td>\n",
       "      <td>0.286711</td>\n",
       "      <td>-0.250495</td>\n",
       "      <td>-0.206698</td>\n",
       "      <td>-0.933654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090645</td>\n",
       "      <td>0.828098</td>\n",
       "      <td>-0.121316</td>\n",
       "      <td>0.813629</td>\n",
       "      <td>-0.992169</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.341678</td>\n",
       "      <td>0.253055</td>\n",
       "      <td>-0.108251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.910284</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>0.446909</td>\n",
       "      <td>-0.280113</td>\n",
       "      <td>-0.247262</td>\n",
       "      <td>-0.460682</td>\n",
       "      <td>0.288947</td>\n",
       "      <td>-0.244630</td>\n",
       "      <td>-0.217923</td>\n",
       "      <td>-0.942812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070928</td>\n",
       "      <td>0.828098</td>\n",
       "      <td>-0.119105</td>\n",
       "      <td>0.813629</td>\n",
       "      <td>-0.986798</td>\n",
       "      <td>0.757730</td>\n",
       "      <td>0.103864</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>0.253055</td>\n",
       "      <td>-0.097807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.899026</td>\n",
       "      <td>-0.625162</td>\n",
       "      <td>0.441594</td>\n",
       "      <td>-0.281975</td>\n",
       "      <td>-0.247262</td>\n",
       "      <td>-0.464881</td>\n",
       "      <td>0.293224</td>\n",
       "      <td>-0.244630</td>\n",
       "      <td>-0.217923</td>\n",
       "      <td>-0.942812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099923</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>-0.119105</td>\n",
       "      <td>0.812651</td>\n",
       "      <td>-0.985407</td>\n",
       "      <td>0.757744</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.253918</td>\n",
       "      <td>-0.093566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.891249 -0.621638  0.417513 -0.284545 -0.251119 -0.463985  0.285838   \n",
       "1 -0.895377 -0.621640  0.430735 -0.274166 -0.251016 -0.459078  0.283579   \n",
       "2 -0.903910 -0.621640  0.446909 -0.274166 -0.249243 -0.459078  0.286711   \n",
       "3 -0.910284 -0.625641  0.446909 -0.280113 -0.247262 -0.460682  0.288947   \n",
       "4 -0.899026 -0.625162  0.441594 -0.281975 -0.247262 -0.464881  0.293224   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.246278 -0.199712 -0.933221  ...  0.078440  0.819481 -0.111247  0.792588   \n",
       "1 -0.248442 -0.206698 -0.933221  ...  0.090645  0.827522 -0.116565  0.808396   \n",
       "2 -0.250495 -0.206698 -0.933654  ...  0.090645  0.828098 -0.121316  0.813629   \n",
       "3 -0.244630 -0.217923 -0.942812  ...  0.070928  0.828098 -0.119105  0.813629   \n",
       "4 -0.244630 -0.217923 -0.942812  ...  0.099923  0.824098 -0.119105  0.812651   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.989658  0.739370  0.144455  0.338889  0.270035 -0.108632  \n",
       "1 -0.994202  0.749294  0.121209  0.340605  0.256826 -0.114984  \n",
       "2 -0.992169  0.753885  0.113314  0.341678  0.253055 -0.108251  \n",
       "3 -0.986798  0.757730  0.103864  0.342186  0.253055 -0.097807  \n",
       "4 -0.985407  0.757744  0.109550  0.343002  0.253918 -0.093566  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>V61</th>\n",
       "      <th>V62</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828890</td>\n",
       "      <td>-0.454174</td>\n",
       "      <td>0.455766</td>\n",
       "      <td>-0.247606</td>\n",
       "      <td>-0.188076</td>\n",
       "      <td>-0.224023</td>\n",
       "      <td>0.312756</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>-0.009786</td>\n",
       "      <td>-0.900262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>-0.084750</td>\n",
       "      <td>0.765140</td>\n",
       "      <td>-0.795153</td>\n",
       "      <td>0.716207</td>\n",
       "      <td>0.538449</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>0.212344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.941897</td>\n",
       "      <td>-0.660175</td>\n",
       "      <td>0.490743</td>\n",
       "      <td>-0.265766</td>\n",
       "      <td>-0.188076</td>\n",
       "      <td>-0.415722</td>\n",
       "      <td>0.312756</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>-0.102622</td>\n",
       "      <td>-0.900262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187805</td>\n",
       "      <td>0.831313</td>\n",
       "      <td>-0.099164</td>\n",
       "      <td>0.799842</td>\n",
       "      <td>-1.000088</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>0.264744</td>\n",
       "      <td>0.301735</td>\n",
       "      <td>0.213469</td>\n",
       "      <td>-0.025478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.958226</td>\n",
       "      <td>-0.660062</td>\n",
       "      <td>0.502027</td>\n",
       "      <td>-0.287051</td>\n",
       "      <td>-0.187320</td>\n",
       "      <td>-0.410712</td>\n",
       "      <td>0.294332</td>\n",
       "      <td>-0.250739</td>\n",
       "      <td>-0.169461</td>\n",
       "      <td>-0.938403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.831313</td>\n",
       "      <td>-0.107606</td>\n",
       "      <td>0.811020</td>\n",
       "      <td>-0.972163</td>\n",
       "      <td>0.741404</td>\n",
       "      <td>0.140587</td>\n",
       "      <td>0.305364</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>-0.041757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.958226</td>\n",
       "      <td>-0.660062</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>-0.290792</td>\n",
       "      <td>-0.180015</td>\n",
       "      <td>-0.403985</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>-0.250739</td>\n",
       "      <td>-0.169461</td>\n",
       "      <td>-0.938403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.838909</td>\n",
       "      <td>-0.107058</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>-0.972163</td>\n",
       "      <td>0.747084</td>\n",
       "      <td>0.140587</td>\n",
       "      <td>0.312955</td>\n",
       "      <td>0.199819</td>\n",
       "      <td>-0.041757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.943833</td>\n",
       "      <td>-0.665081</td>\n",
       "      <td>0.510912</td>\n",
       "      <td>-0.290792</td>\n",
       "      <td>-0.179064</td>\n",
       "      <td>-0.403985</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>-0.203349</td>\n",
       "      <td>-0.965674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086085</td>\n",
       "      <td>0.838909</td>\n",
       "      <td>-0.105862</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>-0.971566</td>\n",
       "      <td>0.747084</td>\n",
       "      <td>0.135664</td>\n",
       "      <td>0.317206</td>\n",
       "      <td>0.199819</td>\n",
       "      <td>-0.032188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.828890 -0.454174  0.455766 -0.247606 -0.188076 -0.224023  0.312756   \n",
       "1 -0.941897 -0.660175  0.490743 -0.265766 -0.188076 -0.415722  0.312756   \n",
       "2 -0.958226 -0.660062  0.502027 -0.287051 -0.187320 -0.410712  0.294332   \n",
       "3 -0.958226 -0.660062  0.510766 -0.290792 -0.180015 -0.403985  0.298800   \n",
       "4 -0.943833 -0.665081  0.510912 -0.290792 -0.179064 -0.403985  0.305384   \n",
       "\n",
       "         V8        V9       V10  ...       V55       V56       V57       V58  \\\n",
       "0 -0.212926 -0.009786 -0.900262  ...  0.255959  0.828395 -0.084750  0.765140   \n",
       "1 -0.212926 -0.102622 -0.900262  ...  0.187805  0.831313 -0.099164  0.799842   \n",
       "2 -0.250739 -0.169461 -0.938403  ...  0.083367  0.831313 -0.107606  0.811020   \n",
       "3 -0.250739 -0.169461 -0.938403  ...  0.083367  0.838909 -0.107058  0.821125   \n",
       "4 -0.253059 -0.203349 -0.965674  ...  0.086085  0.838909 -0.105862  0.822775   \n",
       "\n",
       "        V59       V60       V61       V62       V63       V64  \n",
       "0 -0.795153  0.716207  0.538449  0.301600  0.232086  0.212344  \n",
       "1 -1.000088  0.732326  0.264744  0.301735  0.213469 -0.025478  \n",
       "2 -0.972163  0.741404  0.140587  0.305364  0.211290 -0.041757  \n",
       "3 -0.972163  0.747084  0.140587  0.312955  0.199819 -0.041757  \n",
       "4 -0.971566  0.747084  0.135664  0.317206  0.199819 -0.032188  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_repr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af2d87a9baae9e19220b6d245f822c980479669c4aad7c3aadfe7a700f0cdbad"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
